{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "04_senet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQfhYcVF8KPt"
      },
      "source": [
        "# Squeeze and Excitation Network (SENet)\n",
        "\n",
        "---\n",
        "\n",
        "## 目的\n",
        "SENetの構造を理解する.\n",
        "\n",
        "SENetを用いてCIFAR-10データセットに対する物体認識を行う．\n",
        "\n",
        "## Squeeze and Excitation Network (SENet)\n",
        "\n",
        "SENetとは，ILSVRC2017で優勝したモデルであり，認識に有益なチャネルに対して重み付けすることで認識精度の高精度化を実現しました．SENet は，特徴マップにGlobal Average Pooling (GAP) を施し，$1×1$の畳み込み処理を行うことで各チャネルに対する重みを獲得します．その後，特徴マップの各チャネルごとに重み付けを行います．これにより，認識に有益なチャネルに対して重点的に学習することができます．\n",
        "SENetは汎用性が高く，従来のあらゆるモデル (e.g., VGG, ResNet) に導入することができます．\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/u8btdc5cfu8dq03/senet.png?dl=1\" width=100%>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ehSX6U8KPv"
      },
      "source": [
        "## モジュールのインポート\n",
        "プログラムの実行に必要なモジュールをインポートします．\n",
        "今回は，機械学習ライブラリであるPytorchを使用します．\n",
        "PyTorchとは，Python向けのオープンソース機械学習ライブラリで，Facebookに開発されました．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaNXqInW8KPv"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchsummary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4gEy7cGCfz8"
      },
      "source": [
        "## GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "下記のコードを実行してGPU情報を確認します． GPUの確認を行うためには，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．\n",
        "\n",
        "`Use CUDA: True`と表示されれば，GPUを使用した計算をPytorchで行うことが可能です． CPUとなっている場合は，上記に記載している手順にしたがって，設定を変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9fjeG_U8KP1",
        "outputId": "f9103370-d94b-4f30-d9d7-94c7a613c97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "use_cuda = torch.cuda.is_available()\n",
        "cudnn.benchmark = True\n",
        "print('Use CUDA:', use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uanw74k0F9iw"
      },
      "source": [
        "下記のコードを実行してGPU情報を確認します．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeUIUazLGGPu",
        "outputId": "c1fc60b3-f549-40a2-d05b-80559bc6ef3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug 23 16:28:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    28W /  70W |   1495MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJiKvt08lkjY"
      },
      "source": [
        "## 使用するデータセット\n",
        "\n",
        "### データセット\n",
        "今回の物体認識では，CIFAR-10データセットを使用します．CIFAR-10データセットは，飛行機や犬などの10クラスの物体が表示されている画像から構成されたデータセットです．\n",
        "\n",
        "![CIFAR10_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176458/b6b43478-c85f-9211-7bc6-227d9b387af5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNzvYQL58KP4"
      },
      "source": [
        "### データセットのダウンロードと読み込み\n",
        "実験に使用するCIFAR-10データセットを読み込みます．\n",
        "１回の誤差を算出するデータ数 (ミニバッチサイズ) は，256とします．\n",
        "まず，CIFAR-10データセットをダウンロードします．\n",
        "次に，ダウンロードしたデータセットを読み込みます．\n",
        "学習には，大量のデータを利用しますが，それでも十分ではありません． そこで，データ拡張 (data augmentation) により，データのバリエーションを増やします． 一般的な方法は，画像の左右反転，明るさ変換などです．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leWJTOIL8KP4",
        "outputId": "c9640a7d-65f3-4ecf-fe0a-df7b9656031d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=20)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=20)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHQfAwb_8KP7"
      },
      "source": [
        "### CIFAR-10データセットの表示\n",
        "CIFAR-10データセットに含まれる画像を表示してみます．\n",
        "ここでは，matplotlibを用いて複数の画像を表示させるプログラムを利用します．\n",
        "学習データは5万枚，1つのデータサイズは3x32x32の画像のような形式となっています． これは32x32ピクセルのカラー画像という意味になります．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fod_SRFR8KP8",
        "outputId": "627bcb68-bad3-40e2-d7be-c32e376734ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    npimg = ((npimg.transpose((1,2,0))  * [0.2023, 0.1994, 0.2010]) + [0.4914, 0.4822, 0.4465])  # unnormalize\n",
        "    plt.imshow(npimg)\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[0:4]))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  cat  ship  ship plane\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DduOi-s18KP_"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "次に，SENetを定義します．\n",
        "今回は，ResNetにSENetを導入したモデル (SE-ResNet) を使用します．SE-ResNetの層の深さ (depth) は，110層に設定します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0cpWP_w8KP_",
        "outputId": "0e576775-3c8b-4ff8-f7ed-d2ae50311347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        \"\"\"\n",
        "        if planes == 16:\n",
        "            self.globalAvgPool = nn.AvgPool2d(32, stride=1)\n",
        "        elif planes == 32:\n",
        "            self.globalAvgPool = nn.AvgPool2d(16, stride=1)\n",
        "        elif planes == 64:\n",
        "            if down_size:\n",
        "                self.globalAvgPool = nn.AvgPool2d(8, stride=1)\n",
        "            else:\n",
        "                self.globalAvgPool = nn.AvgPool2d(16, stride=1)\n",
        "        \"\"\"\n",
        "        self.globalAvgPool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(in_features=planes, out_features=planes // 4)\n",
        "        self.fc2 = nn.Linear(in_features=planes // 4, out_features=planes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        # SE Block\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "        #out = out + original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \"\"\"\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            if down_size:\n",
        "                self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "            else:\n",
        "                self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        \"\"\"\n",
        "        self.globalAvgPool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(in_features=planes * 4, out_features=planes * 4 // 16)\n",
        "        self.fc2 = nn.Linear(in_features=planes * 4 // 16, out_features=planes * 4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        # SE Block\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0),out.size(1),1,1)\n",
        "        out = out * original_out\n",
        "        #out = out + original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SE_ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, depth, num_classes=10):\n",
        "        super(SE_ResNet, self).__init__()\n",
        "        # Model type specifies number of layers for CIFAR-10 model\n",
        "        block_name = 'Bottleneck' if depth >=44 else 'BasicBlock'\n",
        "        if block_name.lower() == 'basicblock':\n",
        "            assert (depth - 2) % 6 == 0, 'When use basicblock, depth should be 6n+2, e.g. 20, 32, 44'\n",
        "            n = (depth - 2) // 6\n",
        "            block = BasicBlock\n",
        "        elif block_name.lower() == 'bottleneck':\n",
        "            assert (depth - 2) % 9 == 0, 'When use bottleneck, depth should be 9n+2, e.g. 47, 56, 110, 1199'\n",
        "            n = (depth - 2) // 9\n",
        "            block = Bottleneck\n",
        "        else:\n",
        "            raise ValueError('block_name shoule be Basicblock or Bottleneck')\n",
        "\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, n)\n",
        "        self.layer2 = self._make_layer(block, 32, n, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, n, stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)    # 32x32\n",
        "\n",
        "        x = self.layer1(x)  # 32x32\n",
        "        x = self.layer2(x)  # 16x16\n",
        "        x = self.layer3(x)  # 8x8\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "depth = 20 # e.g. 20, 32, 44, 47, 56, 110, 1199\n",
        "model = SE_ResNet(depth)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SE_ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=16, out_features=4, bias=True)\n",
              "      (fc2): Linear(in_features=4, out_features=16, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=16, out_features=4, bias=True)\n",
              "      (fc2): Linear(in_features=4, out_features=16, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=16, out_features=4, bias=True)\n",
              "      (fc2): Linear(in_features=4, out_features=16, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
              "      (fc2): Linear(in_features=8, out_features=32, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
              "      (fc2): Linear(in_features=8, out_features=32, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
              "      (fc2): Linear(in_features=8, out_features=32, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
              "      (fc2): Linear(in_features=16, out_features=64, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
              "      (fc2): Linear(in_features=16, out_features=64, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (globalAvgPool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
              "      (fc2): Linear(in_features=16, out_features=64, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFCekfs78KQC"
      },
      "source": [
        "## 損失関数と最適化手法の定義\n",
        "学習に使用する損失関数と最適化手法を定義します．\n",
        "`scheduler`で学習率のスケジューリングを行います．\n",
        "`scheduler`では，初期の学習率を0.1に設定し，全体のエポック数の1/2と3/4で学習率を0.1倍します．\n",
        "各更新において，学習用データと教師データをそれぞれ`inputs`と`targets`とします．\n",
        "学習モデルに`inputs`を与えて，SENetの出力を取得します．\n",
        "SENetの出力と教師ラベル`targets`との誤差を`criterion`で算出します．\n",
        "また，認識精度も算出します．\n",
        "そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．\n",
        "最適化手法には，確率的勾配降下法 (stochastic gradient descent: SGD) を用いて学習します．\n",
        "\n",
        "最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rntVJhx98KQC"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[50, 75], gamma=0.1) # 50 < 75\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4NRFd6i8KQF"
      },
      "source": [
        "## 学習\n",
        "学習エポック数を100とします．\n",
        "CIFAR-10の学習データサイズを取得し，1エポック内における更新回数を求めます．\n",
        "1エポック学習するごとに学習したモデルを評価し，最も精度の高いモデルが保存されます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnMVTad98KQG",
        "outputId": "d7c8b7d7-50c2-43ff-f4a3-8a3c44968e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 100\n",
        "best_acc = 0  # best test accuracy\n",
        "\n",
        "# Training\n",
        "for epoch in range(epochs):\n",
        "    scheduler.step()\n",
        "    train_running_loss = 0.0\n",
        "    train_running_acc = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    count = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # print statistics\n",
        "        train_running_loss += loss\n",
        "        train_running_acc += 100.*correct/total\n",
        "        count += 1\n",
        "\n",
        "    print('[Epoch %d] Train Loss: %.5f | Train Acc: %.3f%%'\n",
        "                  % (epoch + 1, train_loss/count, train_running_acc/count))\n",
        "    \n",
        "    # testing\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        test_running_loss = 0.0\n",
        "        test_running_acc = 0.0\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        count = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # print statistics\n",
        "            test_running_loss += loss\n",
        "            test_running_acc += 100.*correct/total\n",
        "            count += 1\n",
        "\n",
        "        print('Test Loss: %.5f | Test Acc: %.3f%%'\n",
        "                      % (test_loss/count, test_running_acc/count))\n",
        "        \n",
        "    # save model\n",
        "    if test_running_acc/count > best_acc:\n",
        "        best_acc = max(test_running_acc/count, best_acc)\n",
        "        PATH = './cifar_net.pth'\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1] Train Loss: 1.64972 | Train Acc: 28.988%\n",
            "Test Loss: 1.45358 | Test Acc: 48.213%\n",
            "[Epoch 2] Train Loss: 1.17172 | Train Acc: 54.107%\n",
            "Test Loss: 1.17734 | Test Acc: 56.919%\n",
            "[Epoch 3] Train Loss: 0.95358 | Train Acc: 64.312%\n",
            "Test Loss: 1.50504 | Test Acc: 52.415%\n",
            "[Epoch 4] Train Loss: 0.82157 | Train Acc: 69.582%\n",
            "Test Loss: 0.91721 | Test Acc: 69.001%\n",
            "[Epoch 5] Train Loss: 0.71727 | Train Acc: 74.566%\n",
            "Test Loss: 0.78993 | Test Acc: 73.323%\n",
            "[Epoch 6] Train Loss: 0.65389 | Train Acc: 76.677%\n",
            "Test Loss: 0.73123 | Test Acc: 75.927%\n",
            "[Epoch 7] Train Loss: 0.61752 | Train Acc: 78.083%\n",
            "Test Loss: 0.75942 | Test Acc: 74.838%\n",
            "[Epoch 8] Train Loss: 0.57687 | Train Acc: 79.745%\n",
            "Test Loss: 0.89822 | Test Acc: 70.149%\n",
            "[Epoch 9] Train Loss: 0.55123 | Train Acc: 81.037%\n",
            "Test Loss: 0.56641 | Test Acc: 80.955%\n",
            "[Epoch 10] Train Loss: 0.53182 | Train Acc: 81.347%\n",
            "Test Loss: 0.68215 | Test Acc: 76.573%\n",
            "[Epoch 11] Train Loss: 0.51403 | Train Acc: 82.193%\n",
            "Test Loss: 0.73936 | Test Acc: 76.059%\n",
            "[Epoch 12] Train Loss: 0.49482 | Train Acc: 83.192%\n",
            "Test Loss: 0.68207 | Test Acc: 77.370%\n",
            "[Epoch 13] Train Loss: 0.48752 | Train Acc: 83.196%\n",
            "Test Loss: 0.69315 | Test Acc: 77.350%\n",
            "[Epoch 14] Train Loss: 0.47627 | Train Acc: 83.365%\n",
            "Test Loss: 0.54117 | Test Acc: 81.276%\n",
            "[Epoch 15] Train Loss: 0.46457 | Train Acc: 83.797%\n",
            "Test Loss: 0.61273 | Test Acc: 79.633%\n",
            "[Epoch 16] Train Loss: 0.45857 | Train Acc: 83.976%\n",
            "Test Loss: 0.83385 | Test Acc: 74.753%\n",
            "[Epoch 17] Train Loss: 0.44702 | Train Acc: 84.152%\n",
            "Test Loss: 1.80142 | Test Acc: 55.934%\n",
            "[Epoch 18] Train Loss: 0.43878 | Train Acc: 84.647%\n",
            "Test Loss: 0.59441 | Test Acc: 79.924%\n",
            "[Epoch 19] Train Loss: 0.43628 | Train Acc: 85.072%\n",
            "Test Loss: 0.59155 | Test Acc: 80.036%\n",
            "[Epoch 20] Train Loss: 0.42866 | Train Acc: 85.689%\n",
            "Test Loss: 0.58257 | Test Acc: 79.983%\n",
            "[Epoch 21] Train Loss: 0.42336 | Train Acc: 85.173%\n",
            "Test Loss: 1.02799 | Test Acc: 70.713%\n",
            "[Epoch 22] Train Loss: 0.41568 | Train Acc: 86.043%\n",
            "Test Loss: 0.55953 | Test Acc: 81.312%\n",
            "[Epoch 23] Train Loss: 0.42125 | Train Acc: 85.560%\n",
            "Test Loss: 0.62556 | Test Acc: 80.370%\n",
            "[Epoch 24] Train Loss: 0.40928 | Train Acc: 85.798%\n",
            "Test Loss: 0.56932 | Test Acc: 81.487%\n",
            "[Epoch 25] Train Loss: 0.39981 | Train Acc: 86.704%\n",
            "Test Loss: 0.59050 | Test Acc: 80.127%\n",
            "[Epoch 26] Train Loss: 0.39793 | Train Acc: 86.318%\n",
            "Test Loss: 0.62191 | Test Acc: 80.154%\n",
            "[Epoch 27] Train Loss: 0.39542 | Train Acc: 86.348%\n",
            "Test Loss: 0.62315 | Test Acc: 79.519%\n",
            "[Epoch 28] Train Loss: 0.38957 | Train Acc: 86.688%\n",
            "Test Loss: 0.66398 | Test Acc: 77.399%\n",
            "[Epoch 29] Train Loss: 0.38233 | Train Acc: 86.659%\n",
            "Test Loss: 0.75045 | Test Acc: 76.593%\n",
            "[Epoch 30] Train Loss: 0.38196 | Train Acc: 87.148%\n",
            "Test Loss: 0.59856 | Test Acc: 80.189%\n",
            "[Epoch 31] Train Loss: 0.38074 | Train Acc: 86.647%\n",
            "Test Loss: 0.57551 | Test Acc: 80.548%\n",
            "[Epoch 32] Train Loss: 0.37942 | Train Acc: 86.632%\n",
            "Test Loss: 0.60439 | Test Acc: 78.826%\n",
            "[Epoch 33] Train Loss: 0.37801 | Train Acc: 87.292%\n",
            "Test Loss: 0.71620 | Test Acc: 77.667%\n",
            "[Epoch 34] Train Loss: 0.37967 | Train Acc: 86.904%\n",
            "Test Loss: 0.56915 | Test Acc: 80.430%\n",
            "[Epoch 35] Train Loss: 0.37111 | Train Acc: 87.478%\n",
            "Test Loss: 0.73287 | Test Acc: 75.801%\n",
            "[Epoch 36] Train Loss: 0.37115 | Train Acc: 87.070%\n",
            "Test Loss: 0.51681 | Test Acc: 82.344%\n",
            "[Epoch 37] Train Loss: 0.36925 | Train Acc: 87.243%\n",
            "Test Loss: 0.59731 | Test Acc: 80.009%\n",
            "[Epoch 38] Train Loss: 0.36560 | Train Acc: 87.316%\n",
            "Test Loss: 0.61095 | Test Acc: 79.956%\n",
            "[Epoch 39] Train Loss: 0.36104 | Train Acc: 87.619%\n",
            "Test Loss: 0.53720 | Test Acc: 81.960%\n",
            "[Epoch 40] Train Loss: 0.36226 | Train Acc: 87.655%\n",
            "Test Loss: 0.53097 | Test Acc: 81.810%\n",
            "[Epoch 41] Train Loss: 0.35944 | Train Acc: 87.909%\n",
            "Test Loss: 0.58164 | Test Acc: 81.178%\n",
            "[Epoch 42] Train Loss: 0.36054 | Train Acc: 87.353%\n",
            "Test Loss: 0.72888 | Test Acc: 77.587%\n",
            "[Epoch 43] Train Loss: 0.35003 | Train Acc: 88.044%\n",
            "Test Loss: 0.60879 | Test Acc: 79.991%\n",
            "[Epoch 44] Train Loss: 0.35298 | Train Acc: 87.663%\n",
            "Test Loss: 0.55547 | Test Acc: 81.188%\n",
            "[Epoch 45] Train Loss: 0.35720 | Train Acc: 87.887%\n",
            "Test Loss: 0.72726 | Test Acc: 76.597%\n",
            "[Epoch 46] Train Loss: 0.35271 | Train Acc: 87.789%\n",
            "Test Loss: 0.71380 | Test Acc: 77.687%\n",
            "[Epoch 47] Train Loss: 0.35045 | Train Acc: 88.176%\n",
            "Test Loss: 0.55083 | Test Acc: 82.238%\n",
            "[Epoch 48] Train Loss: 0.34672 | Train Acc: 88.213%\n",
            "Test Loss: 0.60053 | Test Acc: 80.473%\n",
            "[Epoch 49] Train Loss: 0.34371 | Train Acc: 88.366%\n",
            "Test Loss: 0.48307 | Test Acc: 83.941%\n",
            "[Epoch 50] Train Loss: 0.34670 | Train Acc: 87.849%\n",
            "Test Loss: 0.58887 | Test Acc: 81.082%\n",
            "[Epoch 51] Train Loss: 0.34650 | Train Acc: 88.352%\n",
            "Test Loss: 0.59502 | Test Acc: 81.091%\n",
            "[Epoch 52] Train Loss: 0.34297 | Train Acc: 88.241%\n",
            "Test Loss: 0.63933 | Test Acc: 80.344%\n",
            "[Epoch 53] Train Loss: 0.33816 | Train Acc: 88.378%\n",
            "Test Loss: 0.57734 | Test Acc: 80.790%\n",
            "[Epoch 54] Train Loss: 0.34630 | Train Acc: 87.972%\n",
            "Test Loss: 0.54776 | Test Acc: 81.433%\n",
            "[Epoch 55] Train Loss: 0.34050 | Train Acc: 88.374%\n",
            "Test Loss: 0.52451 | Test Acc: 82.799%\n",
            "[Epoch 56] Train Loss: 0.33892 | Train Acc: 88.650%\n",
            "Test Loss: 0.86964 | Test Acc: 75.347%\n",
            "[Epoch 57] Train Loss: 0.34146 | Train Acc: 88.123%\n",
            "Test Loss: 0.70131 | Test Acc: 76.581%\n",
            "[Epoch 58] Train Loss: 0.33622 | Train Acc: 88.802%\n",
            "Test Loss: 0.50338 | Test Acc: 82.847%\n",
            "[Epoch 59] Train Loss: 0.33719 | Train Acc: 88.330%\n",
            "Test Loss: 0.61882 | Test Acc: 81.386%\n",
            "[Epoch 60] Train Loss: 0.34483 | Train Acc: 88.348%\n",
            "Test Loss: 0.55843 | Test Acc: 81.798%\n",
            "[Epoch 61] Train Loss: 0.32785 | Train Acc: 88.396%\n",
            "Test Loss: 0.55024 | Test Acc: 82.618%\n",
            "[Epoch 62] Train Loss: 0.33281 | Train Acc: 88.551%\n",
            "Test Loss: 0.54019 | Test Acc: 81.463%\n",
            "[Epoch 63] Train Loss: 0.33879 | Train Acc: 88.772%\n",
            "Test Loss: 0.69820 | Test Acc: 78.215%\n",
            "[Epoch 64] Train Loss: 0.32865 | Train Acc: 88.625%\n",
            "Test Loss: 0.63568 | Test Acc: 78.824%\n",
            "[Epoch 65] Train Loss: 0.33561 | Train Acc: 88.351%\n",
            "Test Loss: 0.55351 | Test Acc: 81.497%\n",
            "[Epoch 66] Train Loss: 0.33681 | Train Acc: 88.689%\n",
            "Test Loss: 0.49349 | Test Acc: 82.602%\n",
            "[Epoch 67] Train Loss: 0.32576 | Train Acc: 88.746%\n",
            "Test Loss: 0.54897 | Test Acc: 81.840%\n",
            "[Epoch 68] Train Loss: 0.33146 | Train Acc: 88.856%\n",
            "Test Loss: 0.47466 | Test Acc: 84.018%\n",
            "[Epoch 69] Train Loss: 0.33169 | Train Acc: 88.663%\n",
            "Test Loss: 0.57720 | Test Acc: 82.002%\n",
            "[Epoch 70] Train Loss: 0.32481 | Train Acc: 89.039%\n",
            "Test Loss: 0.49804 | Test Acc: 83.712%\n",
            "[Epoch 71] Train Loss: 0.33314 | Train Acc: 88.694%\n",
            "Test Loss: 0.51322 | Test Acc: 82.580%\n",
            "[Epoch 72] Train Loss: 0.32066 | Train Acc: 88.814%\n",
            "Test Loss: 0.63298 | Test Acc: 79.591%\n",
            "[Epoch 73] Train Loss: 0.32521 | Train Acc: 88.592%\n",
            "Test Loss: 0.47933 | Test Acc: 84.280%\n",
            "[Epoch 74] Train Loss: 0.32611 | Train Acc: 88.857%\n",
            "Test Loss: 0.76140 | Test Acc: 77.630%\n",
            "[Epoch 75] Train Loss: 0.32665 | Train Acc: 88.609%\n",
            "Test Loss: 0.44257 | Test Acc: 84.441%\n",
            "[Epoch 76] Train Loss: 0.33022 | Train Acc: 88.518%\n",
            "Test Loss: 0.59044 | Test Acc: 81.029%\n",
            "[Epoch 77] Train Loss: 0.31762 | Train Acc: 89.264%\n",
            "Test Loss: 0.51240 | Test Acc: 83.253%\n",
            "[Epoch 78] Train Loss: 0.32209 | Train Acc: 88.918%\n",
            "Test Loss: 0.56341 | Test Acc: 82.155%\n",
            "[Epoch 79] Train Loss: 0.31919 | Train Acc: 89.352%\n",
            "Test Loss: 0.59614 | Test Acc: 81.350%\n",
            "[Epoch 80] Train Loss: 0.32728 | Train Acc: 88.970%\n",
            "Test Loss: 0.55098 | Test Acc: 82.259%\n",
            "[Epoch 81] Train Loss: 0.32342 | Train Acc: 89.126%\n",
            "Test Loss: 0.66001 | Test Acc: 78.476%\n",
            "[Epoch 82] Train Loss: 0.31883 | Train Acc: 89.233%\n",
            "Test Loss: 0.55076 | Test Acc: 81.339%\n",
            "[Epoch 83] Train Loss: 0.31925 | Train Acc: 89.097%\n",
            "Test Loss: 0.48700 | Test Acc: 83.755%\n",
            "[Epoch 84] Train Loss: 0.31964 | Train Acc: 89.125%\n",
            "Test Loss: 0.53496 | Test Acc: 82.651%\n",
            "[Epoch 85] Train Loss: 0.32391 | Train Acc: 88.964%\n",
            "Test Loss: 0.59980 | Test Acc: 80.846%\n",
            "[Epoch 86] Train Loss: 0.31720 | Train Acc: 89.002%\n",
            "Test Loss: 0.55056 | Test Acc: 82.982%\n",
            "[Epoch 87] Train Loss: 0.32369 | Train Acc: 88.717%\n",
            "Test Loss: 0.44096 | Test Acc: 84.845%\n",
            "[Epoch 88] Train Loss: 0.31653 | Train Acc: 89.100%\n",
            "Test Loss: 0.48307 | Test Acc: 83.511%\n",
            "[Epoch 89] Train Loss: 0.31861 | Train Acc: 89.111%\n",
            "Test Loss: 0.57081 | Test Acc: 80.231%\n",
            "[Epoch 90] Train Loss: 0.31650 | Train Acc: 89.217%\n",
            "Test Loss: 0.48513 | Test Acc: 83.058%\n",
            "[Epoch 91] Train Loss: 0.31519 | Train Acc: 89.237%\n",
            "Test Loss: 0.56168 | Test Acc: 81.886%\n",
            "[Epoch 92] Train Loss: 0.31992 | Train Acc: 88.956%\n",
            "Test Loss: 0.42493 | Test Acc: 85.797%\n",
            "[Epoch 93] Train Loss: 0.31591 | Train Acc: 89.535%\n",
            "Test Loss: 0.55453 | Test Acc: 82.089%\n",
            "[Epoch 94] Train Loss: 0.31289 | Train Acc: 88.937%\n",
            "Test Loss: 0.54992 | Test Acc: 81.928%\n",
            "[Epoch 95] Train Loss: 0.31885 | Train Acc: 88.743%\n",
            "Test Loss: 0.57935 | Test Acc: 81.089%\n",
            "[Epoch 96] Train Loss: 0.31064 | Train Acc: 89.189%\n",
            "Test Loss: 0.76487 | Test Acc: 76.862%\n",
            "[Epoch 97] Train Loss: 0.32296 | Train Acc: 88.804%\n",
            "Test Loss: 0.49606 | Test Acc: 83.705%\n",
            "[Epoch 98] Train Loss: 0.31619 | Train Acc: 89.168%\n",
            "Test Loss: 0.63122 | Test Acc: 80.030%\n",
            "[Epoch 99] Train Loss: 0.31748 | Train Acc: 88.979%\n",
            "Test Loss: 0.59441 | Test Acc: 81.601%\n",
            "[Epoch 100] Train Loss: 0.31206 | Train Acc: 89.516%\n",
            "Test Loss: 0.65171 | Test Acc: 79.785%\n",
            "[Epoch 101] Train Loss: 0.31272 | Train Acc: 89.520%\n",
            "Test Loss: 0.46514 | Test Acc: 84.327%\n",
            "[Epoch 102] Train Loss: 0.30992 | Train Acc: 89.707%\n",
            "Test Loss: 0.51144 | Test Acc: 83.404%\n",
            "[Epoch 103] Train Loss: 0.30967 | Train Acc: 89.116%\n",
            "Test Loss: 0.53691 | Test Acc: 82.426%\n",
            "[Epoch 104] Train Loss: 0.31371 | Train Acc: 89.173%\n",
            "Test Loss: 0.51318 | Test Acc: 83.175%\n",
            "[Epoch 105] Train Loss: 0.30814 | Train Acc: 89.746%\n",
            "Test Loss: 0.63598 | Test Acc: 79.744%\n",
            "[Epoch 106] Train Loss: 0.30964 | Train Acc: 89.253%\n",
            "Test Loss: 0.54234 | Test Acc: 82.200%\n",
            "[Epoch 107] Train Loss: 0.31130 | Train Acc: 89.243%\n",
            "Test Loss: 0.49654 | Test Acc: 83.402%\n",
            "[Epoch 108] Train Loss: 0.30903 | Train Acc: 89.285%\n",
            "Test Loss: 0.75275 | Test Acc: 77.847%\n",
            "[Epoch 109] Train Loss: 0.31276 | Train Acc: 89.034%\n",
            "Test Loss: 0.51951 | Test Acc: 82.181%\n",
            "[Epoch 110] Train Loss: 0.30645 | Train Acc: 89.701%\n",
            "Test Loss: 0.54029 | Test Acc: 81.955%\n",
            "[Epoch 111] Train Loss: 0.30795 | Train Acc: 89.354%\n",
            "Test Loss: 0.52993 | Test Acc: 83.157%\n",
            "[Epoch 112] Train Loss: 0.30904 | Train Acc: 89.671%\n",
            "Test Loss: 0.60943 | Test Acc: 80.821%\n",
            "[Epoch 113] Train Loss: 0.30497 | Train Acc: 89.481%\n",
            "Test Loss: 0.59382 | Test Acc: 79.714%\n",
            "[Epoch 114] Train Loss: 0.30350 | Train Acc: 89.790%\n",
            "Test Loss: 0.49913 | Test Acc: 83.473%\n",
            "[Epoch 115] Train Loss: 0.30650 | Train Acc: 89.549%\n",
            "Test Loss: 0.55060 | Test Acc: 81.853%\n",
            "[Epoch 116] Train Loss: 0.30754 | Train Acc: 89.352%\n",
            "Test Loss: 0.57951 | Test Acc: 82.056%\n",
            "[Epoch 117] Train Loss: 0.30799 | Train Acc: 89.630%\n",
            "Test Loss: 0.55495 | Test Acc: 82.501%\n",
            "[Epoch 118] Train Loss: 0.30677 | Train Acc: 89.558%\n",
            "Test Loss: 0.44618 | Test Acc: 84.938%\n",
            "[Epoch 119] Train Loss: 0.30651 | Train Acc: 89.656%\n",
            "Test Loss: 0.42399 | Test Acc: 85.847%\n",
            "[Epoch 120] Train Loss: 0.30830 | Train Acc: 89.707%\n",
            "Test Loss: 0.53098 | Test Acc: 81.990%\n",
            "[Epoch 121] Train Loss: 0.30529 | Train Acc: 89.457%\n",
            "Test Loss: 0.77010 | Test Acc: 76.523%\n",
            "[Epoch 122] Train Loss: 0.30338 | Train Acc: 89.923%\n",
            "Test Loss: 0.57903 | Test Acc: 81.542%\n",
            "[Epoch 123] Train Loss: 0.31154 | Train Acc: 89.303%\n",
            "Test Loss: 0.62223 | Test Acc: 80.604%\n",
            "[Epoch 124] Train Loss: 0.30267 | Train Acc: 89.818%\n",
            "Test Loss: 0.40786 | Test Acc: 86.746%\n",
            "[Epoch 125] Train Loss: 0.30690 | Train Acc: 89.791%\n",
            "Test Loss: 0.52576 | Test Acc: 84.046%\n",
            "[Epoch 126] Train Loss: 0.30168 | Train Acc: 89.827%\n",
            "Test Loss: 0.72927 | Test Acc: 76.737%\n",
            "[Epoch 127] Train Loss: 0.30711 | Train Acc: 89.593%\n",
            "Test Loss: 0.44654 | Test Acc: 84.024%\n",
            "[Epoch 128] Train Loss: 0.30751 | Train Acc: 89.519%\n",
            "Test Loss: 0.53175 | Test Acc: 82.415%\n",
            "[Epoch 129] Train Loss: 0.30500 | Train Acc: 89.449%\n",
            "Test Loss: 0.47486 | Test Acc: 84.138%\n",
            "[Epoch 130] Train Loss: 0.30513 | Train Acc: 89.605%\n",
            "Test Loss: 0.70848 | Test Acc: 78.646%\n",
            "[Epoch 131] Train Loss: 0.29722 | Train Acc: 90.013%\n",
            "Test Loss: 0.51836 | Test Acc: 82.596%\n",
            "[Epoch 132] Train Loss: 0.30440 | Train Acc: 89.743%\n",
            "Test Loss: 0.54313 | Test Acc: 81.118%\n",
            "[Epoch 133] Train Loss: 0.30254 | Train Acc: 89.562%\n",
            "Test Loss: 0.47729 | Test Acc: 84.006%\n",
            "[Epoch 134] Train Loss: 0.29523 | Train Acc: 89.735%\n",
            "Test Loss: 0.76944 | Test Acc: 77.063%\n",
            "[Epoch 135] Train Loss: 0.29978 | Train Acc: 89.899%\n",
            "Test Loss: 0.51772 | Test Acc: 84.135%\n",
            "[Epoch 136] Train Loss: 0.30501 | Train Acc: 89.619%\n",
            "Test Loss: 0.54616 | Test Acc: 81.971%\n",
            "[Epoch 137] Train Loss: 0.29914 | Train Acc: 89.267%\n",
            "Test Loss: 0.61454 | Test Acc: 80.293%\n",
            "[Epoch 138] Train Loss: 0.30095 | Train Acc: 89.977%\n",
            "Test Loss: 0.47688 | Test Acc: 84.543%\n",
            "[Epoch 139] Train Loss: 0.30627 | Train Acc: 89.072%\n",
            "Test Loss: 0.49795 | Test Acc: 84.265%\n",
            "[Epoch 140] Train Loss: 0.29915 | Train Acc: 89.531%\n",
            "Test Loss: 0.54493 | Test Acc: 82.639%\n",
            "[Epoch 141] Train Loss: 0.30315 | Train Acc: 89.445%\n",
            "Test Loss: 0.45762 | Test Acc: 84.811%\n",
            "[Epoch 142] Train Loss: 0.30212 | Train Acc: 89.866%\n",
            "Test Loss: 0.58144 | Test Acc: 80.555%\n",
            "[Epoch 143] Train Loss: 0.29424 | Train Acc: 89.913%\n",
            "Test Loss: 0.58609 | Test Acc: 81.125%\n",
            "[Epoch 144] Train Loss: 0.30147 | Train Acc: 89.847%\n",
            "Test Loss: 0.46331 | Test Acc: 83.975%\n",
            "[Epoch 145] Train Loss: 0.30046 | Train Acc: 89.845%\n",
            "Test Loss: 0.51245 | Test Acc: 83.193%\n",
            "[Epoch 146] Train Loss: 0.29741 | Train Acc: 89.650%\n",
            "Test Loss: 0.58451 | Test Acc: 81.285%\n",
            "[Epoch 147] Train Loss: 0.30508 | Train Acc: 90.066%\n",
            "Test Loss: 0.51781 | Test Acc: 83.025%\n",
            "[Epoch 148] Train Loss: 0.29422 | Train Acc: 89.942%\n",
            "Test Loss: 0.58365 | Test Acc: 81.084%\n",
            "[Epoch 149] Train Loss: 0.31168 | Train Acc: 89.233%\n",
            "Test Loss: 0.55061 | Test Acc: 82.200%\n",
            "[Epoch 150] Train Loss: 0.19398 | Train Acc: 92.356%\n",
            "Test Loss: 0.24537 | Test Acc: 91.719%\n",
            "[Epoch 151] Train Loss: 0.15192 | Train Acc: 94.898%\n",
            "Test Loss: 0.23416 | Test Acc: 92.268%\n",
            "[Epoch 152] Train Loss: 0.13915 | Train Acc: 95.393%\n",
            "Test Loss: 0.23612 | Test Acc: 92.356%\n",
            "[Epoch 153] Train Loss: 0.13051 | Train Acc: 95.613%\n",
            "Test Loss: 0.23142 | Test Acc: 92.401%\n",
            "[Epoch 154] Train Loss: 0.12307 | Train Acc: 95.952%\n",
            "Test Loss: 0.22776 | Test Acc: 92.623%\n",
            "[Epoch 155] Train Loss: 0.11669 | Train Acc: 96.318%\n",
            "Test Loss: 0.23743 | Test Acc: 92.668%\n",
            "[Epoch 156] Train Loss: 0.11026 | Train Acc: 96.415%\n",
            "Test Loss: 0.23273 | Test Acc: 92.751%\n",
            "[Epoch 157] Train Loss: 0.10656 | Train Acc: 96.522%\n",
            "Test Loss: 0.23211 | Test Acc: 92.574%\n",
            "[Epoch 158] Train Loss: 0.10434 | Train Acc: 96.612%\n",
            "Test Loss: 0.23299 | Test Acc: 92.789%\n",
            "[Epoch 159] Train Loss: 0.10055 | Train Acc: 96.851%\n",
            "Test Loss: 0.23568 | Test Acc: 92.584%\n",
            "[Epoch 160] Train Loss: 0.09342 | Train Acc: 96.875%\n",
            "Test Loss: 0.23723 | Test Acc: 92.434%\n",
            "[Epoch 161] Train Loss: 0.09353 | Train Acc: 97.012%\n",
            "Test Loss: 0.23576 | Test Acc: 92.530%\n",
            "[Epoch 162] Train Loss: 0.08931 | Train Acc: 97.168%\n",
            "Test Loss: 0.23106 | Test Acc: 92.919%\n",
            "[Epoch 163] Train Loss: 0.08621 | Train Acc: 97.151%\n",
            "Test Loss: 0.23697 | Test Acc: 92.698%\n",
            "[Epoch 164] Train Loss: 0.08159 | Train Acc: 97.449%\n",
            "Test Loss: 0.25499 | Test Acc: 92.213%\n",
            "[Epoch 165] Train Loss: 0.08368 | Train Acc: 97.255%\n",
            "Test Loss: 0.24679 | Test Acc: 92.351%\n",
            "[Epoch 166] Train Loss: 0.08014 | Train Acc: 97.556%\n",
            "Test Loss: 0.24664 | Test Acc: 92.426%\n",
            "[Epoch 167] Train Loss: 0.07897 | Train Acc: 97.407%\n",
            "Test Loss: 0.24142 | Test Acc: 92.763%\n",
            "[Epoch 168] Train Loss: 0.07608 | Train Acc: 97.592%\n",
            "Test Loss: 0.25607 | Test Acc: 92.348%\n",
            "[Epoch 169] Train Loss: 0.07341 | Train Acc: 97.601%\n",
            "Test Loss: 0.24281 | Test Acc: 92.689%\n",
            "[Epoch 170] Train Loss: 0.07132 | Train Acc: 97.768%\n",
            "Test Loss: 0.26296 | Test Acc: 92.257%\n",
            "[Epoch 171] Train Loss: 0.07078 | Train Acc: 97.858%\n",
            "Test Loss: 0.25042 | Test Acc: 92.594%\n",
            "[Epoch 172] Train Loss: 0.06775 | Train Acc: 97.929%\n",
            "Test Loss: 0.25764 | Test Acc: 92.504%\n",
            "[Epoch 173] Train Loss: 0.06823 | Train Acc: 97.782%\n",
            "Test Loss: 0.25606 | Test Acc: 92.537%\n",
            "[Epoch 174] Train Loss: 0.06796 | Train Acc: 97.940%\n",
            "Test Loss: 0.26424 | Test Acc: 92.483%\n",
            "[Epoch 175] Train Loss: 0.06593 | Train Acc: 97.960%\n",
            "Test Loss: 0.27484 | Test Acc: 92.025%\n",
            "[Epoch 176] Train Loss: 0.06241 | Train Acc: 98.067%\n",
            "Test Loss: 0.26888 | Test Acc: 92.485%\n",
            "[Epoch 177] Train Loss: 0.06245 | Train Acc: 98.166%\n",
            "Test Loss: 0.26314 | Test Acc: 92.562%\n",
            "[Epoch 178] Train Loss: 0.06231 | Train Acc: 98.039%\n",
            "Test Loss: 0.26433 | Test Acc: 92.403%\n",
            "[Epoch 179] Train Loss: 0.06339 | Train Acc: 97.988%\n",
            "Test Loss: 0.26888 | Test Acc: 92.216%\n",
            "[Epoch 180] Train Loss: 0.06081 | Train Acc: 98.126%\n",
            "Test Loss: 0.27253 | Test Acc: 92.313%\n",
            "[Epoch 181] Train Loss: 0.06396 | Train Acc: 97.821%\n",
            "Test Loss: 0.26787 | Test Acc: 92.456%\n",
            "[Epoch 182] Train Loss: 0.06021 | Train Acc: 98.026%\n",
            "Test Loss: 0.27816 | Test Acc: 92.201%\n",
            "[Epoch 183] Train Loss: 0.05742 | Train Acc: 98.329%\n",
            "Test Loss: 0.27921 | Test Acc: 92.185%\n",
            "[Epoch 184] Train Loss: 0.05972 | Train Acc: 98.143%\n",
            "Test Loss: 0.27606 | Test Acc: 92.106%\n",
            "[Epoch 185] Train Loss: 0.06024 | Train Acc: 98.246%\n",
            "Test Loss: 0.27466 | Test Acc: 92.171%\n",
            "[Epoch 186] Train Loss: 0.06386 | Train Acc: 98.008%\n",
            "Test Loss: 0.28678 | Test Acc: 91.907%\n",
            "[Epoch 187] Train Loss: 0.05843 | Train Acc: 98.165%\n",
            "Test Loss: 0.26817 | Test Acc: 92.335%\n",
            "[Epoch 188] Train Loss: 0.06069 | Train Acc: 98.056%\n",
            "Test Loss: 0.28156 | Test Acc: 91.739%\n",
            "[Epoch 189] Train Loss: 0.05715 | Train Acc: 98.304%\n",
            "Test Loss: 0.28267 | Test Acc: 91.865%\n",
            "[Epoch 190] Train Loss: 0.05967 | Train Acc: 98.309%\n",
            "Test Loss: 0.27831 | Test Acc: 91.800%\n",
            "[Epoch 191] Train Loss: 0.05583 | Train Acc: 98.314%\n",
            "Test Loss: 0.27877 | Test Acc: 92.400%\n",
            "[Epoch 192] Train Loss: 0.05930 | Train Acc: 98.296%\n",
            "Test Loss: 0.27765 | Test Acc: 92.139%\n",
            "[Epoch 193] Train Loss: 0.05896 | Train Acc: 98.248%\n",
            "Test Loss: 0.28472 | Test Acc: 91.894%\n",
            "[Epoch 194] Train Loss: 0.05918 | Train Acc: 98.199%\n",
            "Test Loss: 0.26829 | Test Acc: 92.475%\n",
            "[Epoch 195] Train Loss: 0.05750 | Train Acc: 98.119%\n",
            "Test Loss: 0.29206 | Test Acc: 91.538%\n",
            "[Epoch 196] Train Loss: 0.06110 | Train Acc: 98.123%\n",
            "Test Loss: 0.27793 | Test Acc: 92.250%\n",
            "[Epoch 197] Train Loss: 0.05908 | Train Acc: 98.157%\n",
            "Test Loss: 0.28334 | Test Acc: 92.178%\n",
            "[Epoch 198] Train Loss: 0.05860 | Train Acc: 98.230%\n",
            "Test Loss: 0.28853 | Test Acc: 92.052%\n",
            "[Epoch 199] Train Loss: 0.05949 | Train Acc: 98.269%\n",
            "Test Loss: 0.29593 | Test Acc: 91.872%\n",
            "[Epoch 200] Train Loss: 0.06089 | Train Acc: 97.954%\n",
            "Test Loss: 0.29518 | Test Acc: 91.932%\n",
            "[Epoch 201] Train Loss: 0.06142 | Train Acc: 98.169%\n",
            "Test Loss: 0.28762 | Test Acc: 91.762%\n",
            "[Epoch 202] Train Loss: 0.05978 | Train Acc: 98.168%\n",
            "Test Loss: 0.29610 | Test Acc: 91.670%\n",
            "[Epoch 203] Train Loss: 0.06066 | Train Acc: 98.067%\n",
            "Test Loss: 0.27939 | Test Acc: 91.949%\n",
            "[Epoch 204] Train Loss: 0.06119 | Train Acc: 98.070%\n",
            "Test Loss: 0.29648 | Test Acc: 91.682%\n",
            "[Epoch 205] Train Loss: 0.06402 | Train Acc: 97.881%\n",
            "Test Loss: 0.27904 | Test Acc: 91.910%\n",
            "[Epoch 206] Train Loss: 0.06565 | Train Acc: 97.870%\n",
            "Test Loss: 0.30445 | Test Acc: 91.681%\n",
            "[Epoch 207] Train Loss: 0.06012 | Train Acc: 98.062%\n",
            "Test Loss: 0.28978 | Test Acc: 91.450%\n",
            "[Epoch 208] Train Loss: 0.05959 | Train Acc: 98.178%\n",
            "Test Loss: 0.30024 | Test Acc: 91.112%\n",
            "[Epoch 209] Train Loss: 0.05847 | Train Acc: 98.245%\n",
            "Test Loss: 0.30675 | Test Acc: 91.885%\n",
            "[Epoch 210] Train Loss: 0.06731 | Train Acc: 97.910%\n",
            "Test Loss: 0.29071 | Test Acc: 91.358%\n",
            "[Epoch 211] Train Loss: 0.06519 | Train Acc: 97.829%\n",
            "Test Loss: 0.29329 | Test Acc: 91.852%\n",
            "[Epoch 212] Train Loss: 0.06272 | Train Acc: 98.047%\n",
            "Test Loss: 0.29001 | Test Acc: 91.977%\n",
            "[Epoch 213] Train Loss: 0.06286 | Train Acc: 98.149%\n",
            "Test Loss: 0.30647 | Test Acc: 91.311%\n",
            "[Epoch 214] Train Loss: 0.06958 | Train Acc: 97.637%\n",
            "Test Loss: 0.32349 | Test Acc: 91.118%\n",
            "[Epoch 215] Train Loss: 0.06310 | Train Acc: 97.917%\n",
            "Test Loss: 0.33486 | Test Acc: 90.671%\n",
            "[Epoch 216] Train Loss: 0.06302 | Train Acc: 97.957%\n",
            "Test Loss: 0.30715 | Test Acc: 91.523%\n",
            "[Epoch 217] Train Loss: 0.06074 | Train Acc: 98.195%\n",
            "Test Loss: 0.30800 | Test Acc: 91.299%\n",
            "[Epoch 218] Train Loss: 0.06269 | Train Acc: 97.978%\n",
            "Test Loss: 0.27966 | Test Acc: 92.280%\n",
            "[Epoch 219] Train Loss: 0.06478 | Train Acc: 97.877%\n",
            "Test Loss: 0.33792 | Test Acc: 90.386%\n",
            "[Epoch 220] Train Loss: 0.06712 | Train Acc: 97.673%\n",
            "Test Loss: 0.29847 | Test Acc: 91.302%\n",
            "[Epoch 221] Train Loss: 0.06522 | Train Acc: 97.894%\n",
            "Test Loss: 0.33931 | Test Acc: 90.672%\n",
            "[Epoch 222] Train Loss: 0.06361 | Train Acc: 97.962%\n",
            "Test Loss: 0.33522 | Test Acc: 91.126%\n",
            "[Epoch 223] Train Loss: 0.06392 | Train Acc: 97.900%\n",
            "Test Loss: 0.29955 | Test Acc: 91.613%\n",
            "[Epoch 224] Train Loss: 0.06741 | Train Acc: 97.911%\n",
            "Test Loss: 0.30437 | Test Acc: 91.256%\n",
            "[Epoch 225] Train Loss: 0.04590 | Train Acc: 98.382%\n",
            "Test Loss: 0.24111 | Test Acc: 93.040%\n",
            "[Epoch 226] Train Loss: 0.03250 | Train Acc: 99.190%\n",
            "Test Loss: 0.23839 | Test Acc: 93.107%\n",
            "[Epoch 227] Train Loss: 0.02910 | Train Acc: 99.213%\n",
            "Test Loss: 0.23920 | Test Acc: 93.142%\n",
            "[Epoch 228] Train Loss: 0.02702 | Train Acc: 99.367%\n",
            "Test Loss: 0.24026 | Test Acc: 93.303%\n",
            "[Epoch 229] Train Loss: 0.02575 | Train Acc: 99.407%\n",
            "Test Loss: 0.24396 | Test Acc: 92.951%\n",
            "[Epoch 230] Train Loss: 0.02358 | Train Acc: 99.519%\n",
            "Test Loss: 0.23848 | Test Acc: 93.282%\n",
            "[Epoch 231] Train Loss: 0.02296 | Train Acc: 99.513%\n",
            "Test Loss: 0.24133 | Test Acc: 93.138%\n",
            "[Epoch 232] Train Loss: 0.02181 | Train Acc: 99.514%\n",
            "Test Loss: 0.24206 | Test Acc: 93.085%\n",
            "[Epoch 233] Train Loss: 0.02186 | Train Acc: 99.538%\n",
            "Test Loss: 0.23921 | Test Acc: 93.203%\n",
            "[Epoch 234] Train Loss: 0.02219 | Train Acc: 99.583%\n",
            "Test Loss: 0.24253 | Test Acc: 93.026%\n",
            "[Epoch 235] Train Loss: 0.02171 | Train Acc: 99.568%\n",
            "Test Loss: 0.24222 | Test Acc: 93.176%\n",
            "[Epoch 236] Train Loss: 0.02076 | Train Acc: 99.577%\n",
            "Test Loss: 0.24465 | Test Acc: 92.998%\n",
            "[Epoch 237] Train Loss: 0.02107 | Train Acc: 99.568%\n",
            "Test Loss: 0.24567 | Test Acc: 93.212%\n",
            "[Epoch 238] Train Loss: 0.01924 | Train Acc: 99.585%\n",
            "Test Loss: 0.24143 | Test Acc: 93.304%\n",
            "[Epoch 239] Train Loss: 0.01900 | Train Acc: 99.640%\n",
            "Test Loss: 0.24412 | Test Acc: 93.175%\n",
            "[Epoch 240] Train Loss: 0.01848 | Train Acc: 99.703%\n",
            "Test Loss: 0.24654 | Test Acc: 93.092%\n",
            "[Epoch 241] Train Loss: 0.01827 | Train Acc: 99.673%\n",
            "Test Loss: 0.24465 | Test Acc: 93.085%\n",
            "[Epoch 242] Train Loss: 0.01779 | Train Acc: 99.690%\n",
            "Test Loss: 0.24456 | Test Acc: 93.122%\n",
            "[Epoch 243] Train Loss: 0.01866 | Train Acc: 99.663%\n",
            "Test Loss: 0.24352 | Test Acc: 93.270%\n",
            "[Epoch 244] Train Loss: 0.01648 | Train Acc: 99.743%\n",
            "Test Loss: 0.24452 | Test Acc: 93.236%\n",
            "[Epoch 245] Train Loss: 0.01732 | Train Acc: 99.701%\n",
            "Test Loss: 0.24711 | Test Acc: 93.132%\n",
            "[Epoch 246] Train Loss: 0.01758 | Train Acc: 99.683%\n",
            "Test Loss: 0.24453 | Test Acc: 93.187%\n",
            "[Epoch 247] Train Loss: 0.01658 | Train Acc: 99.728%\n",
            "Test Loss: 0.24527 | Test Acc: 93.170%\n",
            "[Epoch 248] Train Loss: 0.01739 | Train Acc: 99.658%\n",
            "Test Loss: 0.24780 | Test Acc: 93.057%\n",
            "[Epoch 249] Train Loss: 0.01664 | Train Acc: 99.745%\n",
            "Test Loss: 0.25158 | Test Acc: 93.141%\n",
            "[Epoch 250] Train Loss: 0.01655 | Train Acc: 99.663%\n",
            "Test Loss: 0.24831 | Test Acc: 93.214%\n",
            "[Epoch 251] Train Loss: 0.01661 | Train Acc: 99.707%\n",
            "Test Loss: 0.24920 | Test Acc: 92.975%\n",
            "[Epoch 252] Train Loss: 0.01635 | Train Acc: 99.703%\n",
            "Test Loss: 0.25019 | Test Acc: 92.954%\n",
            "[Epoch 253] Train Loss: 0.01532 | Train Acc: 99.745%\n",
            "Test Loss: 0.24873 | Test Acc: 93.082%\n",
            "[Epoch 254] Train Loss: 0.01562 | Train Acc: 99.707%\n",
            "Test Loss: 0.25280 | Test Acc: 92.993%\n",
            "[Epoch 255] Train Loss: 0.01490 | Train Acc: 99.732%\n",
            "Test Loss: 0.25211 | Test Acc: 93.177%\n",
            "[Epoch 256] Train Loss: 0.01515 | Train Acc: 99.776%\n",
            "Test Loss: 0.24955 | Test Acc: 93.114%\n",
            "[Epoch 257] Train Loss: 0.01485 | Train Acc: 99.811%\n",
            "Test Loss: 0.25365 | Test Acc: 93.030%\n",
            "[Epoch 258] Train Loss: 0.01469 | Train Acc: 99.793%\n",
            "Test Loss: 0.25034 | Test Acc: 93.223%\n",
            "[Epoch 259] Train Loss: 0.01483 | Train Acc: 99.757%\n",
            "Test Loss: 0.25030 | Test Acc: 93.082%\n",
            "[Epoch 260] Train Loss: 0.01519 | Train Acc: 99.754%\n",
            "Test Loss: 0.25155 | Test Acc: 93.208%\n",
            "[Epoch 261] Train Loss: 0.01426 | Train Acc: 99.779%\n",
            "Test Loss: 0.25174 | Test Acc: 93.174%\n",
            "[Epoch 262] Train Loss: 0.01465 | Train Acc: 99.773%\n",
            "Test Loss: 0.25267 | Test Acc: 93.118%\n",
            "[Epoch 263] Train Loss: 0.01425 | Train Acc: 99.793%\n",
            "Test Loss: 0.24934 | Test Acc: 93.064%\n",
            "[Epoch 264] Train Loss: 0.01382 | Train Acc: 99.828%\n",
            "Test Loss: 0.25318 | Test Acc: 93.169%\n",
            "[Epoch 265] Train Loss: 0.01369 | Train Acc: 99.847%\n",
            "Test Loss: 0.25245 | Test Acc: 93.087%\n",
            "[Epoch 266] Train Loss: 0.01421 | Train Acc: 99.702%\n",
            "Test Loss: 0.25118 | Test Acc: 93.110%\n",
            "[Epoch 267] Train Loss: 0.01468 | Train Acc: 99.747%\n",
            "Test Loss: 0.25431 | Test Acc: 92.820%\n",
            "[Epoch 268] Train Loss: 0.01388 | Train Acc: 99.796%\n",
            "Test Loss: 0.25280 | Test Acc: 93.109%\n",
            "[Epoch 269] Train Loss: 0.01322 | Train Acc: 99.785%\n",
            "Test Loss: 0.25648 | Test Acc: 92.958%\n",
            "[Epoch 270] Train Loss: 0.01394 | Train Acc: 99.738%\n",
            "Test Loss: 0.25857 | Test Acc: 92.908%\n",
            "[Epoch 271] Train Loss: 0.01330 | Train Acc: 99.830%\n",
            "Test Loss: 0.25522 | Test Acc: 92.948%\n",
            "[Epoch 272] Train Loss: 0.01276 | Train Acc: 99.852%\n",
            "Test Loss: 0.25706 | Test Acc: 92.942%\n",
            "[Epoch 273] Train Loss: 0.01377 | Train Acc: 99.800%\n",
            "Test Loss: 0.25692 | Test Acc: 93.042%\n",
            "[Epoch 274] Train Loss: 0.01333 | Train Acc: 99.796%\n",
            "Test Loss: 0.25358 | Test Acc: 93.048%\n",
            "[Epoch 275] Train Loss: 0.01365 | Train Acc: 99.786%\n",
            "Test Loss: 0.25657 | Test Acc: 92.729%\n",
            "[Epoch 276] Train Loss: 0.01345 | Train Acc: 99.776%\n",
            "Test Loss: 0.25623 | Test Acc: 93.008%\n",
            "[Epoch 277] Train Loss: 0.01328 | Train Acc: 99.738%\n",
            "Test Loss: 0.25553 | Test Acc: 92.958%\n",
            "[Epoch 278] Train Loss: 0.01300 | Train Acc: 99.815%\n",
            "Test Loss: 0.25819 | Test Acc: 92.986%\n",
            "[Epoch 279] Train Loss: 0.01307 | Train Acc: 99.811%\n",
            "Test Loss: 0.25596 | Test Acc: 93.083%\n",
            "[Epoch 280] Train Loss: 0.01249 | Train Acc: 99.848%\n",
            "Test Loss: 0.25872 | Test Acc: 93.020%\n",
            "[Epoch 281] Train Loss: 0.01293 | Train Acc: 99.818%\n",
            "Test Loss: 0.25853 | Test Acc: 93.089%\n",
            "[Epoch 282] Train Loss: 0.01210 | Train Acc: 99.833%\n",
            "Test Loss: 0.25584 | Test Acc: 92.974%\n",
            "[Epoch 283] Train Loss: 0.01291 | Train Acc: 99.825%\n",
            "Test Loss: 0.25532 | Test Acc: 92.912%\n",
            "[Epoch 284] Train Loss: 0.01257 | Train Acc: 99.816%\n",
            "Test Loss: 0.25851 | Test Acc: 92.958%\n",
            "[Epoch 285] Train Loss: 0.01299 | Train Acc: 99.784%\n",
            "Test Loss: 0.26345 | Test Acc: 93.065%\n",
            "[Epoch 286] Train Loss: 0.01242 | Train Acc: 99.817%\n",
            "Test Loss: 0.26187 | Test Acc: 92.970%\n",
            "[Epoch 287] Train Loss: 0.01262 | Train Acc: 99.817%\n",
            "Test Loss: 0.26269 | Test Acc: 93.146%\n",
            "[Epoch 288] Train Loss: 0.01244 | Train Acc: 99.812%\n",
            "Test Loss: 0.26233 | Test Acc: 93.041%\n",
            "[Epoch 289] Train Loss: 0.01304 | Train Acc: 99.812%\n",
            "Test Loss: 0.26168 | Test Acc: 93.013%\n",
            "[Epoch 290] Train Loss: 0.01213 | Train Acc: 99.813%\n",
            "Test Loss: 0.26218 | Test Acc: 93.028%\n",
            "[Epoch 291] Train Loss: 0.01208 | Train Acc: 99.811%\n",
            "Test Loss: 0.26079 | Test Acc: 92.982%\n",
            "[Epoch 292] Train Loss: 0.01156 | Train Acc: 99.856%\n",
            "Test Loss: 0.26073 | Test Acc: 92.836%\n",
            "[Epoch 293] Train Loss: 0.01218 | Train Acc: 99.816%\n",
            "Test Loss: 0.26596 | Test Acc: 93.078%\n",
            "[Epoch 294] Train Loss: 0.01169 | Train Acc: 99.847%\n",
            "Test Loss: 0.26576 | Test Acc: 92.955%\n",
            "[Epoch 295] Train Loss: 0.01132 | Train Acc: 99.819%\n",
            "Test Loss: 0.26186 | Test Acc: 92.972%\n",
            "[Epoch 296] Train Loss: 0.01242 | Train Acc: 99.845%\n",
            "Test Loss: 0.26164 | Test Acc: 92.980%\n",
            "[Epoch 297] Train Loss: 0.01155 | Train Acc: 99.845%\n",
            "Test Loss: 0.26499 | Test Acc: 92.833%\n",
            "[Epoch 298] Train Loss: 0.01174 | Train Acc: 99.846%\n",
            "Test Loss: 0.26165 | Test Acc: 92.870%\n",
            "[Epoch 299] Train Loss: 0.01225 | Train Acc: 99.817%\n",
            "Test Loss: 0.26016 | Test Acc: 92.952%\n",
            "[Epoch 300] Train Loss: 0.01143 | Train Acc: 99.875%\n",
            "Test Loss: 0.26619 | Test Acc: 92.757%\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlOo-rzY8KQL"
      },
      "source": [
        "##テスト\n",
        "学習したネットワークのテストデータに対する認識率の確認を行います．まず，学習したネットワークを評価するために保存したモデルをロードします．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSa0ATFj8KQP",
        "outputId": "16e0bf2a-c6e6-4f9d-de68-465ae70fc6c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "depth = 20 #e.g. 20, 32, 44, 47, 56, 110, 1199\n",
        "model = SE_ResNet(depth)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwWfJO358KQS"
      },
      "source": [
        "次に，学習したネットワークを用いて，テストデータに対する認識率の確認を行います．\n",
        "`model.eval()`を適用することで，ネットワーク演算を評価モードへ変更します． これにより，学習時と評価時で挙動が異なる演算（dropout等）を変更することが可能です． また，`torch.no_grad()`を適用することで，学習時には必要になる勾配情報を保持することなく演算を行います．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij38kQBP8KQS",
        "outputId": "c633cd77-8dff-4652-fd8b-c19f9a203b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# testing\n",
        "model.eval() \n",
        "with torch.no_grad():\n",
        "    test_running_loss = 0.0\n",
        "    test_running_acc = 0.0\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    count = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # print statistics\n",
        "        test_running_loss += loss\n",
        "        test_running_acc += 100.*correct/total\n",
        "        count += 1\n",
        "\n",
        "    print('Test Loss: %.5f | Test Acc: %.3f%%'\n",
        "                  % (test_loss/count, test_running_acc/count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.24143 | Test Acc: 93.304%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiY_kiXb8KQV"
      },
      "source": [
        "## 課題\n",
        "1. エポック数やミニバッチサイズを変えて実験しましょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AQOyIMFfwo4"
      },
      "source": [
        "#ここにコードを書く"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oypMA_2LfxGr"
      },
      "source": [
        "2. SE-ResNetの層数を変えて精度の変化を比較しましょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F10--iYf2Xq"
      },
      "source": [
        "#ここにコードを書く"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}