{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJU2RPpSvlQT"
   },
   "source": [
    "# PyTorchを用いたCNNによる画像認識 (データセットの作成・Data Augumentation)\n",
    "\n",
    "\n",
    "---\n",
    "## 目的\n",
    "CIFAR-10 Datasetの10クラスの物体認識をPyTorchを用いて行う．\n",
    "\n",
    "GPUを用いたネットワークの計算を行う．また，Data Augmentationを用いた学習の効果について確認する．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rQGfxWYK_4O"
   },
   "source": [
    "## 準備\n",
    "\n",
    "### Google Colaboratoryの設定確認・変更\n",
    "本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n",
    "**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2tsYagqvloK"
   },
   "source": [
    "## 使用するデータセット\n",
    "\n",
    "### データセット\n",
    "今回の物体認識では，[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)データセットを用います．CIFAR-10データセットは，飛行機や犬などの10クラスの物体が表示されている画像から構成されたデータセットです．\n",
    "\n",
    "![CIFAR10_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176458/b6b43478-c85f-9211-7bc6-227d9b387af5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo4jjpmwvle1"
   },
   "source": [
    "## モジュールのインポート\n",
    "はじめに，必要なモジュールをインポートしたのち，GPUを使用した計算が可能かどうかを確認します．\n",
    "\n",
    "### GPUの確認\n",
    "GPUを使用した計算が可能かどうかを確認します．\n",
    "\n",
    "`GPU availability: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n",
    "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iCeaCulfvlao"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a25fedb4e85a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# モジュールのインポート\n",
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from random import randint\n",
    "\n",
    "# GPUの確認\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Use CUDA:', use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppjeW5MbysXC"
   },
   "source": [
    "## データセットの読み込みとData Augmentation\n",
    "\n",
    "学習データ（CIFAR-10データセット）を使用するためのデータセットクラスを作成します．\n",
    "まず，`MyCIFAR10`というクラスを作成します．\n",
    "この際，`torch.utils.data.Dataset`クラスを継承します．\n",
    "\n",
    "### 1. \\_\\_init\\_\\_()\n",
    "`self.__init__(self, ...)`でCIFAR-10データセットのダウンロードと読み込みを行います．\n",
    "まず，`urllib`を用いてwebからCIFAR-10データをダウンロードします．\n",
    "その後，ダウンロードした圧縮ファイルを`tarfile`を用いて解凍します．\n",
    "\n",
    "次に，用意するデータが学習用データか評価用データかを指定し，読み込むファイル名を`download_list`に格納します．\n",
    "\n",
    "CIFAR10データを読み込みます．\n",
    "解凍したフォルダ内にあるデータは，pickle形式となっており，`pickle`モジュールを用いて展開・読み込みを行います．\n",
    "\n",
    "### 2. \\_\\_len\\_\\_()\n",
    "`__len__(self)`ではデータセットのサンプル数を返すように定義します．\n",
    "今回は，`self.data`に格納されている画像データの枚数を返す様に定義します．\n",
    "（学習用データでは50,000枚，評価用データは10,000枚）\n",
    "\n",
    "### 3. \\_\\_getitem\\_\\_()\n",
    "`__getitem__(self, item)`では，`item`で指定した番号のサンプルを読み込んで返すように定義を行います．\n",
    "まず，`item`番目の画像データと対応するラベルを取得します．\n",
    "\n",
    "次に，`self.train`が`True`の場合は，data augmentationを適用させます．\n",
    "ここでは，`MyCIFAR10`クラス内の`_random_crop`と`_random_horizontal_flip`メソッドを使用し，ランダムに画像の切り取りと左右反転を適用します．\n",
    "\n",
    "その後，画像データの画素値を0~1の範囲の値になる様に正規化を行い，画像データの配列を`[channel, height, width]`となる様に配列操作を行い，画像データとラベルを返します．\n",
    "\n",
    "### 4. \\_random_crop(), \\_random_horizontal_flip()\n",
    "`_random_crop`と`_random_horizontal_flip`では，メソッドに入力された画像データに対して，それぞれ，ランダムな画像の切り取りと左右反転のdata augmentationを適用します．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "211jYSVoe7xu"
   },
   "outputs": [],
   "source": [
    "class MyCIFAR10(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR10用自作データセットクラス\n",
    "    \"\"\"\n",
    "    \n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    def __init__(self, root, train=True, download=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.download = download\n",
    "\n",
    "        # CIFAR10データのダウンロード\n",
    "        if download:\n",
    "            urllib.request.urlretrieve(self.url, os.path.join(self.root, self.filename))\n",
    "            with tarfile.open(os.path.join(self.root, self.filename), 'r') as tar:\n",
    "                tar.extractall(path=self.root)\n",
    "\n",
    "        # 学習，評価データの判定\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        # データの読み込み\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        for file_name, checksum in downloaded_list:\n",
    "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                entry = pickle.load(f, encoding='latin1')\n",
    "                self.data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.targets.extend(entry['labels'])\n",
    "                else:\n",
    "                    self.targets.extend(entry['fine_labels'])\n",
    "\n",
    "        # リスト形式で保存された画像データをnumpy.arrayに変換\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img, target = self.data[item], self.targets[item]\n",
    "        \n",
    "        # data augmentation\n",
    "        if self.train:\n",
    "            img = self._random_crop(img)\n",
    "            img = self._random_horizontal_flip(img)\n",
    "        \n",
    "        # データの正規化（0~255）\n",
    "        img = img.astype(np.float32) / 255.\n",
    "\n",
    "        # 画像の配列を入れ替え\n",
    "        img = img.transpose(2, 0, 1)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    @staticmethod\n",
    "    def _random_crop(image, min_size=24):\n",
    "        crop_size = randint(24, 32)\n",
    "        \n",
    "        if crop_size == 32:\n",
    "            return image\n",
    "        else:\n",
    "            top = randint(0, 32 - crop_size)\n",
    "            left = randint(0, 32 - crop_size)\n",
    "            image = image[left:left+crop_size, top:top+crop_size, :]\n",
    "            image = cv2.resize(image, (32, 32))\n",
    "            return image\n",
    "\n",
    "    @staticmethod\n",
    "    def _random_horizontal_flip(image):\n",
    "        if randint(0, 1):\n",
    "            image = np.flip(image, axis=0)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-N00s8GwiPas"
   },
   "source": [
    "上で定義したデータセットクラスを用いてCIFAR-10データセットを読み込みます．`download=True`とすることで，Webからデータセットをダウンロードできます．　※このセルを実行したあと，解凍したファイルを左側の「ファイル」一覧から確認して見ましょう．\n",
    "\n",
    "また，読み込んだデータセットクラスの情報を表示します．\n",
    "まず，各データセットが保有しているサンプル数を表示します．\n",
    "データセットクラスに`len()`を適用すると，上で定義した`__len__()`メソッドが呼ばれ，サンプル数を返します．\n",
    "\n",
    "次に，`train_data`のとある1サンプルを読み込みます．\n",
    "`train_data[10]`とすることで，上で定義した`__getitem__()`メソッドが呼ばれ，引数の`item`に`10`が与えられ，10番目のサンプルを返します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_xx-TkVvls6"
   },
   "outputs": [],
   "source": [
    "train_data = MyCIFAR10(root=\"./\", train=True, download=True)\n",
    "test_data = MyCIFAR10(root=\"./\", train=False, download=True)\n",
    "\n",
    "# サンプル数の表示\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "# とあるサンプルの読み込み\n",
    "img, lab = train_data[10]\n",
    "print(img, lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgDd3iX2zmSV"
   },
   "source": [
    "## ネットワークモデルの定義\n",
    "今回用いる畳み込みニューラルネットワーク（CNN）を定義します．\n",
    "ここでは，畳み込み層2層，全結合層3層から構成されるネットワークとします．\n",
    "\n",
    "1層目の畳み込み層は入力チャンネル数が3，出力する特徴マップ数が16，畳み込むフィルタサイズが3x3です．\n",
    "2層目の畳み込み層は入力チャネル数が16，出力する特徴マップ数が32，畳み込むフィルタサイズは同じく3x3です．\n",
    "1つ目の全結合層の入力ユニット数は，1つ前の出力層の出力と対応させるため8x8x32(=2048)，出力は1024としています．\n",
    "次の全結合層は入力・出力共に1024とします，最後の全結合層（出力層）は入力が1024，出力が10です．\n",
    "これらの各層の構成を`__init__`関数で定義します．\n",
    "\n",
    "次に，`forward`関数では，定義した層を接続して処理するように記述します．`forward`関数の引数xは入力データです．それを`__init__`関数で定義した`conv1`に与え，その出力を活性化関数である`relu`関数に与えます．そして，その出力を`pool`に与えて，プーリング処理結果を`h`として出力します．`h`は`conv2`に与えられて畳み込み処理とプーリング処理を行います．そして，出力`h`を`l1`に与えて全結合層の処理を行います．最終的に`l3`の全結合層の処理を行った出力`h`を戻り値としています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNHnp_YczmY3"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
    "        self.l2 = nn.Linear(1024, 1024)\n",
    "        self.l3 = nn.Linear(1024, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.pool(self.relu(self.conv1(x)))\n",
    "        h = self.pool(self.relu(self.conv2(h)))\n",
    "        h = h.view(h.size()[0], -1)\n",
    "        h = self.relu(self.l1(h))\n",
    "        h = self.relu(self.l2(h))\n",
    "        h = self.l3(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dwuvfouzmd7"
   },
   "source": [
    "## ネットワークの作成\n",
    "上のプログラムで定義したネットワークを作成します．\n",
    "\n",
    "CNNクラスを呼び出して，ネットワークモデルを定義します． また，GPUを使う場合（use_cuda == True）には，ネットワークモデルをGPUメモリ上に配置します． これにより，GPUを用いた演算が可能となります．\n",
    "\n",
    "学習を行う際の最適化方法としてモーメンタムSGD（モーメンタム付き確率的勾配降下法）を利用します． また，学習率 (`lr`) を0.01，モーメンタム (`momentum`) を0.9として引数に与えます．\n",
    "\n",
    "最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．畳み込みと全結合層には`Param #`にいくつかの値が存在しますが，これが重みパラメタの数となります．マックスプーリングは単に特徴マップのサイズを削減するだけなので，パラメタは存在しません．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23m79Eq-zmjl"
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# モデルの情報を表示\n",
    "torchsummary.summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUNa9Xe79vAG"
   },
   "source": [
    "## 学習\n",
    "読み込んだCIFAR-10データセットと作成したネットワークを用いて，学習を行います．\n",
    "\n",
    "1回の誤差を算出するデータ数（ミニバッチサイズ）を64，学習エポック数を10とします．\n",
    "\n",
    "次にデータローダーを定義します．\n",
    "データローダーでは，上で読み込んだデータセット（`train_data`）を用いて，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n",
    "この時，`shuffle=True`と設定することで，読み込むデータを毎回ランダムに指定します．\n",
    "\n",
    "次に，誤差関数を設定します．\n",
    "今回は，分類問題を扱うため，クロスエントロピー誤差を計算するための`CrossEntropyLoss`を`criterion`として定義します．\n",
    "\n",
    "そして，学習を開始します．誤差を各エポックごとに表示するために，カウンターを初期化しておきます．\n",
    "\n",
    "各更新において，学習用データと教師データをそれぞれ`image`と`label`とします．\n",
    "学習モデルに`image`を与えて各クラスの確率`y`を取得します．\n",
    "各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
    "また，認識精度も算出します．\n",
    "そして，誤差を`backward`関数で逆伝播し，ネットワークの更新を行います．\n",
    "認識精度も同時に計算して，`print`関数で学習経過における誤差や認識精度を表示します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68RE3RTa76-W"
   },
   "outputs": [],
   "source": [
    "# ミニバッチサイズ・エポック数の設定\n",
    "batch_size = 64\n",
    "epoch_num = 10\n",
    "n_iter = len(train_data) / batch_size\n",
    "\n",
    "# データローダーの設定\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 誤差関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "\n",
    "# ネットワークを学習モードへ変更\n",
    "model.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        y = model(image)\n",
    "\n",
    "        loss = criterion(y, label)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
    "                                                                                 sum_loss / n_iter,\n",
    "                                                                                 count.item() / len(train_loader),\n",
    "                                                                                 time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "119eIrSmzmw6"
   },
   "source": [
    "## テスト\n",
    "学習したネットワークモデルを用いて評価（テスト）を行います．\n",
    "テストは100枚ずつ行うため，batch_sizeは100とします．\n",
    "データをシャッフルする必要はないため，shuffle=Falseとします．\n",
    "学習時と同様に，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n",
    "\n",
    "すべての画像でテストが終わったら，最終的な精度を表示します．\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yoYVMRGLzm1I"
   },
   "outputs": [],
   "source": [
    "# データローダーの準備\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "model.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "\n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "            \n",
    "        y = model(image)\n",
    "\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(\"test accuracy: {}\".format(count.item() / 10000.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVK02ibuYxmX"
   },
   "source": [
    "## torchvision.datasetsクラス\n",
    "\n",
    "CIFAR-10などの一般的なデータセットは`torchvision.datasets`にすでに用意されています．\n",
    "以下では，`torchvision.datasets`に用意されているCIFAR-10データセットを使用した場合のデータセットおよび，data augmentationの準備方法を紹介します．\n",
    "\n",
    "はじめに`torchvision`の`transform`を用いて，各サンプルを読み込む際の前処理を定義します．\n",
    "`transform`には，上で定義した様な左右反転やランダムな切り取りなどの関数が用意されています．\n",
    "これらを`transforms.Compose()`を用いてまとめることで，一連の処理として定義することができます．\n",
    "以下の学習データ用の`transform_train`では，\n",
    "1. ランダムな画像の切り取り\n",
    "2. ランダムな左右反転\n",
    "3. 画像データをtorch.Tensorのオブジェクトへ変換\n",
    "\n",
    "という処理を定義しています．\n",
    "\n",
    "つぎに，`torchvision.datasets.CIFAR10`クラスを使用して，CIFAR-10データセットを準備します．\n",
    "この時，`transform`の引数に上で定義した処理を指定することで，各サンプルを読み込む際に，指定した処理を行った上でデータを返すことが可能です．\n",
    "\n",
    "これらのデータセットクラスを上で行った学習・評価プログラムに使用することで，同様の学習・評価を行うことが可能です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFlejRFvYx1o"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor()])\n",
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gzl4N5rC4j5u"
   },
   "source": [
    "## 課題\n",
    "1. ネットワーク構造を変えて実験しましょう． \n",
    "     * まず，1層目の畳み込み層のフィルタ数を32にしましょう．また，2層目の畳み込み層のフィルタ数を64にしましょう．\n",
    "    * 次に，中間層のユニット数を2048にしましょう．\n",
    "   \n",
    "\n",
    "\n",
    "2. 最適化の方法をAdamに変えて実験しましょう．\n",
    "\n",
    "\n",
    "\n",
    "3. エポック数やミニバッチサイズを変えて実験しましょう．\n",
    "    * まず，ミニバッチサイズを128にしましょう．\n",
    "    * 次に，エポック数を50にしましょう．"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01_cnn_dataloader_augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
