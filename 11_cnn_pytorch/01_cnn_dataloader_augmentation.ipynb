{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"01_cnn_dataloader_augmentation.ipynb","provenance":[{"file_id":"https://github.com/machine-perception-robotics-group/GoogleColabNotebooks/blob/master/MLDL_lecture_notebooks/10-B_objecct_classification_with_cifar10_whitening_augmentation.ipynb","timestamp":1598574332404}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wJU2RPpSvlQT"},"source":["# PyTorchを用いたCNNによる画像認識 (データセットの作成・Data Augumentation)\n","\n","\n","---\n","## 目的\n","CIFAR10 Datasetを用いて10クラスの物体認識を行う．プログラムの構成は，MNISTによる文字認識のプログラムと同様になっているため，基礎的な説明はそちらを参照して頂きたい．このページでは，MNISTによる文字認識のプログラムとの差分について書いていく．\n","\n","GPUを用いたネットワークの計算を行う．\n","また，Data Augmentationを用いた学習の効果について確認する．\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5rQGfxWYK_4O"},"source":["## 準備\n","\n","### Google Colaboratoryの設定確認・変更\n","本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n","**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"C2tsYagqvloK"},"source":["## 使用するデータセット\n","\n","### データセット\n","今回の物体認識では，CIFAR10データセットを用いる．CIFAR10データセットは，飛行機や犬などの10クラスの物体が表示されている画像から構成されたデータセットである．\n","\n","![CIFAR10_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176458/b6b43478-c85f-9211-7bc6-227d9b387af5.png)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xo4jjpmwvle1"},"source":["## モジュールのインポート\n","はじめに必要なモジュールをインポートする．\n","\n","### GPUの確認\n","GPUを使用した計算が可能かどうかを確認します．\n","\n","`GPU availability: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n","Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iCeaCulfvlao","colab":{}},"source":["# モジュールのインポート\n","import os\n","from time import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import torchsummary\n","\n","import cv2\n","import pickle\n","import urllib.request\n","import tarfile\n","from random import randint\n","\n","# GPUの確認\n","use_cuda = torch.cuda.is_available()\n","print('Use CUDA:', use_cuda)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ppjeW5MbysXC"},"source":["## データセットの読み込みとData Augmentation\n","\n","学習データ（CIFAR10データセット）を使用するためのデータセットクラスを作成します．\n","まず，`MyCIFAR10`というクラスを作成します．\n","この際，`torch.utils.data.Dataset`クラスを継承します．\n","\n","### 1. \\_\\_init\\_\\_()\n","`self.__init__(self, ...)`でCIFAR-10データセットのダウンロードと読み込みを行います．\n","まず，`urllib`を用いてwebからCIFAR10データをダウンロードします．\n","その後，ダウンロードした圧縮ファイルを`tarfile`を用いて解凍します．\n","※ 解凍したファイルを左側の「ファイル」一覧から確認して見ましょう．\n","\n","次に，用意するデータが学習用データか評価用データかを指定し，読み込むファイル名を`download_list`に格納します．\n","\n","CIFAR10データを読み込みます．\n","解凍したフォルダ内にあるデータは，pickle形式となっており，`pickle`モジュールを用いて展開・読み込みを行います．\n","\n","### 2. \\_\\_len\\_\\_()\n","`__len__(self)`ではデータセットのサンプル数を返すように定義します．\n","今回は，`self.data`に格納されている画像データの枚数を返す様に定義します．\n","（学習用データでは50,000枚，評価用データは10,000枚）\n","\n","### 3. \\_\\_getitem\\_\\_()\n","`__getitem__(self, item)`では，`item`で指定した番号のサンプルを読み込んで返すように定義を行います．\n","まず，`item`番目の画像データと対応するラベルを取得します．\n","\n","次に，`self.train`が`True`の場合は，data augmentationを適用させます．\n","ここでは，`MyCIFAR10`クラス内の`_random_crop`と`_random_horizontal_flip`メソッドを使用し，ランダムに画像の切り取りと左右反転を適用します．\n","\n","その後，画像データの画素値を0~1の範囲の値になる様に正規化を行い，，画像データの配列を`[channel, height, width]`となる様に配列操作を行い，画像データとラベルを返します．\n","\n","### 4. \\_random_crop(), \\_random_horizontal_flip()\n","`_random_crop`と`_random_horizontal_flip`では，メソッドに入力された画像データに対して，それぞれ，ランダムな画像の切り取りと左右反転のdata augmentationを適用します．\n"]},{"cell_type":"code","metadata":{"id":"211jYSVoe7xu","colab_type":"code","colab":{}},"source":["class MyCIFAR10(torch.utils.data.Dataset):\n","    base_folder = 'cifar-10-batches-py'\n","    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    filename = \"cifar-10-python.tar.gz\"\n","    train_list = [\n","        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n","        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n","        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n","        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n","        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n","    ]\n","    test_list = [\n","        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n","    ]\n","\n","    def __init__(self, root, train=True, download=True):\n","        super().__init__()\n","\n","        self.root = root\n","        self.train = train\n","        self.download = download\n","\n","        # CIFAR10データのダウンロード\n","        if download:\n","            urllib.request.urlretrieve(self.url, os.path.join(self.root, self.filename))\n","            with tarfile.open(os.path.join(self.root, self.filename), 'r') as tar:\n","                tar.extractall(path=self.root)\n","\n","        # 学習，評価データの判定\n","        if self.train:\n","            downloaded_list = self.train_list\n","        else:\n","            downloaded_list = self.test_list\n","\n","        # データの読み込み\n","        self.data = []\n","        self.targets = []\n","\n","        for file_name, checksum in downloaded_list:\n","            file_path = os.path.join(self.root, self.base_folder, file_name)\n","            with open(file_path, 'rb') as f:\n","                entry = pickle.load(f, encoding='latin1')\n","                self.data.append(entry['data'])\n","                if 'labels' in entry:\n","                    self.targets.extend(entry['labels'])\n","                else:\n","                    self.targets.extend(entry['fine_labels'])\n","\n","        # リスト形式で保存された画像データをnumpy.arrayに変換\n","        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n","        self.data = self.data.transpose((0, 2, 3, 1))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, item):\n","        img, target = self.data[item], self.targets[item]\n","        \n","        # data augmentation\n","        if self.train:\n","            img = self._random_crop(img)\n","            img = self._random_horizontal_flip(img)\n","        \n","        # データの正規化（0~255）\n","        img = img.astype(np.float32) / 255.\n","\n","        # 画像の配列を入れ替え\n","        img = img.transpose(2, 0, 1)\n","\n","        return img, target\n","\n","    @staticmethod\n","    def _random_crop(image, min_size=24):\n","        crop_size = randint(24, 32)\n","        \n","        if crop_size == 32:\n","            return image\n","        else:\n","            top = randint(0, 32 - crop_size)\n","            left = randint(0, 32 - crop_size)\n","            image = image[left:left+crop_size, top:top+crop_size, :]\n","            image = cv2.resize(image, (32, 32))\n","            return image\n","\n","    @staticmethod\n","    def _random_horizontal_flip(image):\n","        if randint(0, 1):\n","            image = np.flip(image, axis=0)\n","        return image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-N00s8GwiPas","colab_type":"text"},"source":["上で定義したデータセットクラスを用いてCIFAR10データセットを読み込みます．\n","\n","また，読み込んだデータセットクラスの情報を表示します．\n","まず，各データセットが保有しているサンプル数を表示します．\n","データセットクラスに`len()`を適用すると，上で定義した`__len__()`メソッドが呼ばれ，サンプル数を返します．\n","\n","次に，`train_data`のとある1サンプルを読み込みます．\n","`train_data[10]`とすることで，上で定義した`__getitem__()`メソッドが呼ばれ，引数の`item`に`10`が与えられ，10番目のサンプルを返します．"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K_xx-TkVvls6","colab":{}},"source":["train_data = MyCIFAR10(root=\"./\", train=True, download=True)\n","test_data = MyCIFAR10(root=\"./\", train=False, download=True)\n","\n","# サンプル数の表示\n","print(len(train_data))\n","print(len(test_data))\n","\n","# とあるサンプルの読み込み\n","img, lab = train_data[10]\n","print(img, lab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xgDd3iX2zmSV"},"source":["## ネットワークモデルの定義\n","畳み込みニューラルネットワークを定義します．\n","\n","ここでは，畳み込み層２層，全結合層３層から構成されるネットワークとします．\n","\n","１層目の畳み込み層は入力チャンネル数が１，出力する特徴マップ数が16，畳み込むフィルタサイズが3x3です．２層目の畳み込み層は入力チャネル数が16．出力する特徴マップ数が32，畳み込むフィルタサイズは同じく3x3です．１つ目の全結合層は入力ユニット数は不定とし，出力は1024としています．次の全結合層入力，出力共に1024，出力層は入力が1024，出力が10です．これらの各層の構成を`__init__`関数で定義します．\n","\n","次に，`forward`関数では，定義した層を接続して処理するように記述します．`forward`関数の引数xは入力データです．それを`__init__`関数で定義したconv1に与え，その出力を活性化関数であるrelu関数に与えます．そして，その出力をmax_pooling_2dに与えて，プーリング処理結果をhとして出力します．hはconv2に与えられて畳み込み処理とプーリング処理を行います．そして，出力hをl1に与えて全結合層の処理を行います．最終的にl3の全結合層の処理を行った出力hを戻り値としています．"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TNHnp_YczmY3","colab":{}},"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.relu = nn.ReLU()\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n","        self.l2 = nn.Linear(1024, 1024)\n","        self.l3 = nn.Linear(1024, 10)\n","    \n","    def forward(self, x):\n","        h = self.pool(self.relu(self.conv1(x)))\n","        h = self.pool(self.relu(self.conv2(h)))\n","        h = h.view(h.size()[0], -1)\n","        h = self.relu(self.l1(h))\n","        h = self.relu(self.l2(h))\n","        h = self.l3(h)\n","        return h"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8Dwuvfouzmd7"},"source":["## ネットワークの作成\n","上のプログラムで定義したネットワークを作成します．\n","\n","CNNクラスを呼び出して，ネットワークモデルを定義します． また，GPUを使う場合（use_cuda == True）には，ネットワークモデルをGPUメモリ上に配置します． これにより，GPUを用いた演算が可能となります．\n","\n","学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します． また，学習率を0.01，モーメンタムを0.9として引数に与えます．\n","\n","最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"23m79Eq-zmjl","colab":{}},"source":["model = CNN()\n","if use_cuda:\n","    model.cuda()\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# モデルの情報を表示\n","torchsummary.summary(model, (3, 32, 32))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MUNa9Xe79vAG"},"source":["## 学習\n","読み込んだMNISTデータセットと作成したネットワークを用いて，学習を行います．\n","\n","1回の誤差を算出するデータ数（ミニバッチサイズ）を64，学習エポック数を10とします．\n","\n","次にデータローダーを定義します．\n","データローダーでは，上で読み込んだデータセット（`train_data`）を用いて，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n","この時，`shuffle=True`と設定することで，読み込むデータを毎回ランダムに指定します．\n","\n","次に，誤差関数を設定します．\n","今回は，分類問題をあつかうため，クロスエントロピー誤差を計算するための`CrossEntropyLoss`を`criterion`として定義します．\n","\n","学習を開始します．\n","\n","各更新において，学習用データと教師データをそれぞれ`image`と`label`とします．\n","学習モデルにimageを与えて各クラスの確率yを取得します．\n","各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n","また，認識精度も算出します．\n","そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"68RE3RTa76-W","colab":{}},"source":["# ミニバッチサイズ・エポック数の設定\n","batch_size = 64\n","epoch_num = 10\n","n_iter = len(train_data) / batch_size\n","\n","# データローダーの設定\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","\n","# 誤差関数の設定\n","criterion = nn.CrossEntropyLoss()\n","if use_cuda:\n","    criterion.cuda()\n","\n","# ネットワークを学習モードへ変更\n","model.train()\n","\n","start = time()\n","for epoch in range(1, epoch_num+1):\n","    sum_loss = 0.0\n","    count = 0\n","    \n","    for image, label in train_loader:\n","        \n","        if use_cuda:\n","            image = image.cuda()\n","            label = label.cuda()\n","\n","        y = model(image)\n","\n","        loss = criterion(y, label)\n","        \n","        model.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        sum_loss += loss.item()\n","        \n","        pred = torch.argmax(y, dim=1)\n","        count += torch.sum(pred == label)\n","        \n","    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n","                                                                                 sum_loss / n_iter,\n","                                                                                 count.item() / len(train_loader),\n","                                                                                 time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"119eIrSmzmw6"},"source":["## テスト\n","学習したネットワークモデルを用いて評価を行います．"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yoYVMRGLzm1I","colab":{}},"source":["# データローダーの準備\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n","\n","# ネットワークを評価モードへ変更\n","model.eval()\n","\n","# 評価の実行\n","count = 0\n","with torch.no_grad():\n","    for image, label in test_loader:\n","\n","        if use_cuda:\n","            image = image.cuda()\n","            label = label.cuda()\n","            \n","        y = model(image)\n","\n","        pred = torch.argmax(y, dim=1)\n","        count += torch.sum(pred == label)\n","\n","print(\"test accuracy: {}\".format(count.item() / 10000.))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vVK02ibuYxmX","colab_type":"text"},"source":["## torchvision.datasetsクラス\n","\n","CIFAR10などの一般的なデータセットは`torchvision.datasets`にすでに用意されています．\n","以下では，`torchvision.datasets`に用意されているCIFAR10データセットを使用した場合のデータセットおよび，data augmentationの準備方法を紹介します．\n","\n","はじめに`torchvision`の`transform`を用いて，各サンプルを読み込む際の前処理を定義します．\n","`transform`には，上で定義した様な左右反転やランダムな切り取りなどの関数が用意されています．\n","これらを`transforms.Compose()`によって，まとめて定義することで，一連の処理としてまとめて定義することができます．\n","以下の学習データ用の`transform_train`では，\n","1. ランダムな画像の切り取り\n","2. ランダムな左右反転\n","3. 画像データをtorch.Tensorのオブジェクトへ変換\n","という処理を定義しています．\n","\n","つぎに，`torchvision.datasets.CIFAR10`クラスを使用して，CIFAR10データセットを準備します．\n","この時，`transform`の引数に上で定義した処理を指定することで，各サンプルを読み込む際に，指定した処理を行った上でデータを返すことが可能です．\n","\n","これらのデータセットクラスを上で行った学習・評価プログラムに使用することで，同様の学習・評価を行うことが可能です．"]},{"cell_type":"code","metadata":{"id":"LFlejRFvYx1o","colab_type":"code","colab":{}},"source":["transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor()])\n","transform_test = transforms.Compose([transforms.ToTensor()])\n","\n","train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n","test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Gzl4N5rC4j5u"},"source":["## 課題\n","1. ネットワーク構造を変えて実験しましょう． \n","     * まず，1層目の畳み込み層のフィルタ数を32にしましょう．また，2層目の畳み込み層のフィルタ数を64にしましょう．\n","    * 次に，中間層のユニット数を2048にしましょう．\n","   \n","\n","\n","2. 最適化の方法をAdamに変えて実験しましょう．\n","\n","\n","\n","3. エポック数やミニバッチサイズを変えて実験しましょう．\n","    * まず，ミニバッチサイズを128にしましょう．\n","    * 次に，エポック数を50にしましょう．"]},{"cell_type":"code","metadata":{"id":"MjS-WptIg9Pf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}
