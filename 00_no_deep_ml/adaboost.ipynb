{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07_adaboost.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UqIFEGfHFv57"},"source":["# AdaBoostによる教師あり学習\n","\n","\n","---\n","## 目的\n","AdaBoostを用いて2つのサンプルの識別を行う．その後，交差検定法を用いて識別テストを行う．\n","\n","\n","## プログラムの動作\n","\n","`07_AdaBoost.py`を実行すると，`data/car.txt`と`data/human.txt`の2つ読み込む．次に，AdaBoostによる学習およびテストを交差検定法を用いて行う．最後に，識別率と識別されたグラフを表示する．\n"]},{"cell_type":"markdown","metadata":{"id":"5aYrBRlEsfsp"},"source":["## 準備\n","プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．"]},{"cell_type":"code","metadata":{"id":"JouGYBdrsSNi"},"source":["!wget -q http://www.mprg.cs.chubu.ac.jp/tutorial/ML_Lecture/sklearn/data.zip\n","!unzip -q data.zip\n","!ls\n","!ls ./data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZLojkvIsSVc"},"source":["##モジュールのインポート\n","初めに，必要なモジュールをインポートする．\n","\n","今回は新たに`AdaBoostClassifier`と`DecisionTreeClassifier`をインポートし，2つを組み合わせて用いる．このように，AdaBoostは他の学習方法と組み合わせてパフォーマンスを上げることができる．"]},{"cell_type":"code","metadata":{"id":"iqysOb3lFxKz"},"source":["from os import path\n","import numpy as np\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import metrics\n","from sklearn import model_selection"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VzTVMeYIu12x"},"source":["##データの読み込み\n","次に，テキストファイルを読み込む．\n"]},{"cell_type":"code","metadata":{"id":"K9ZwdH46tA0_"},"source":["in_txt1 = open(path.join('data', 'car.txt'))\n","in_txt2 = open(path.join('data', 'human.txt'))\n","\n","car = np.asarray([(line.strip()).split('\\t') for line in in_txt1], dtype=float)\n","print(car.shape)\n","human = np.asarray([(line.strip()).split('\\t') for line in in_txt2], dtype=float)\n","print(human.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0GLv9PVuu61S"},"source":["## データのラベル付けと結合，交差検定法の準備\n","学習を行う前に，データがcarまたはhumanどちらのクラスに属するかラベル付けをする．"]},{"cell_type":"code","metadata":{"id":"NvCtgdVvu695"},"source":["car_y =  np.zeros(car.shape[0])\n","human_y = np.ones(human.shape[0])\n","X= np.r_[car, human]\n","y= np.r_[car_y, human_y]\n","\n","kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=0)\n","print(X.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWNrbV3PFwU2"},"source":["## 学習と評価\n","for文で学習と評価をk回繰り返す．\n"]},{"cell_type":"code","metadata":{"id":"cyf2RpsUGuV3"},"source":["scores = []\n","best_score = 0.0\n","\n","for train, test in kfold.split(X):\n","    classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200)\n","    classifier.fit(X[train], y[train])\n","    preds = classifier.predict(X[test])\n","    score = metrics.accuracy_score(preds, y[test])\n","    scores.append(score)\n","\n","    if score > best_score:\n","        best_classifier = classifier\n","        best_score = score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgKjZecqFwXd"},"source":["`classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200)`が識別器の定義となる．今回はAdaBoostとDecisionTree（決定木）を用いる．主なパラメータとして`max_depth`と`algorithm`と`n_estimators`がある．\n","\n","- `max_depth`: 決定木の最大の深さ **1のまま変更しないこと**\n","- `algorithm`: 利用するアルゴリズム．`SAMME`と`SAMME.R`がある．\n","- `n_estimators`: 弱識別器の数．\n"]},{"cell_type":"markdown","metadata":{"id":"n8kIXVwvFwZ7"},"source":["## 識別率の計算\n","得られたk個の結果を平均して，識別率を求める．"]},{"cell_type":"code","metadata":{"id":"RA5cPHE0HGW7"},"source":["accuracy = (sum(scores) / len(scores)) * 100\n","msg = 'recognition rate: {accuracy:.2f}%'.format(accuracy=accuracy)\n","print(msg)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"puwLllGzFwcN"},"source":["## グラフの描画\n","識別結果を可視化するためにグラフを作成する．どちらのクラスがどの領域かわかりやすく表示することができる．"]},{"cell_type":"code","metadata":{"id":"WRRg9DjXHKlH"},"source":["import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","subfig = fig.add_subplot(1,1,1)\n","plt.xlim(0, 10000)\n","plt.ylim(20, 50)\n","\n","xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 500),\n","                     np.linspace(plt.ylim()[0], plt.ylim()[1], 500))\n","\n","Z = best_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n","\n","subfig.scatter(car[:,0], car[:,1],color='black')\n","subfig.scatter(human[:,0], human[:,1],color='red')\n","\n","subfig.set_title('Feature Distribution')\n","subfig.set_xlabel('Area')\n","subfig.set_ylabel('complexity')\n","\n","plt.savefig(\"07_graph.png\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ejl5U17_Fweq"},"source":["## 課題\n","1. 弱識別器の数（`n_estimators`）を変化させると識別境界はどう変化するか．グラフで確認せよ．\n","2. 識別率の最も高くなる弱識別器の数（`n_estimators`）を求めよ．\n","\n","\n","## ヒント\n","1. 学習を行いすぎるとどうなるか．\n","2. 200だと若干過学習気味である．もう少し減らしてみると良い．"]}]}