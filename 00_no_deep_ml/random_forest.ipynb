{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08_random_forest.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ay-iV4H4Huyp"},"source":["# RandomForestによる教師あり学習\n","\n","---\n","## 目的\n","RandomForestを用いて2つのサンプルの識別を行う．その後，交差検定法を用いて識別テストを行う．\n","\n","\n","## プログラムの動作\n","`08_RandomForest.py`を実行すると，`data/car.txt`と`data/human.txt`の2つ読み込む．次に，RandomForestによる学習およびテストを交差検定法を用いて行う．最後に，識別率と識別されたグラフを表示する．\n","\n","\n","## プログラムの解説\n","プログラムを上から順番に解説していく．なお，今回も前回，前々回と同じく**第5回と同じプログラムで識別器の定義とモジュールのインポートを変更しただけ**であるため，細かい説明は省略する．わからないところがあれば第5回の解説を読み返すこと．\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5aYrBRlEsfsp"},"source":["## 準備\n","プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．"]},{"cell_type":"code","metadata":{"id":"JouGYBdrsSNi"},"source":["!wget -q http://www.mprg.cs.chubu.ac.jp/tutorial/ML_Lecture/sklearn/data.zip\n","!unzip -q data.zip\n","!ls\n","!ls ./data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZLojkvIsSVc"},"source":["## モジュールのインポート\n","初めに，必要なモジュールをインポートする．\n","\n","今回は新たに`RandomForestClassifier`をインポートする．"]},{"cell_type":"code","metadata":{"id":"iqysOb3lFxKz"},"source":["from os import path\n","import numpy as np\n","from sklearn import metrics\n","from sklearn import model_selection\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VzTVMeYIu12x"},"source":["##データの読み込み\n","次に，テキストファイルを読み込む．"]},{"cell_type":"code","metadata":{"id":"K9ZwdH46tA0_"},"source":["in_txt1 = open(path.join('data', 'car.txt'))\n","in_txt2 = open(path.join('data', 'human.txt'))\n","\n","car = np.asarray([(line.strip()).split('\\t') for line in in_txt1], dtype=float)\n","print(car.shape)\n","human = np.asarray([(line.strip()).split('\\t') for line in in_txt2], dtype=float)\n","print(human.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0GLv9PVuu61S"},"source":["## データのラベル付けと結合，交差検定法の準備\n","学習を行う前に，データがcarまたはhumanどちらのクラスに属するかラベル付けをする．"]},{"cell_type":"code","metadata":{"id":"NvCtgdVvu695"},"source":["car_y =  np.zeros(car.shape[0])\n","human_y = np.ones(human.shape[0])\n","X= np.r_[car, human]\n","y= np.r_[car_y, human_y]\n","\n","kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=0)\n","print(X.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h03o2vrbISwA"},"source":["## 学習と評価\n","for文で学習と評価をk回繰り返す．"]},{"cell_type":"code","metadata":{"id":"dS4wo3zjHu_I"},"source":["scores = []\n","best_score = 0.0\n","\n","for train, test in kfold.split(X):\n","    classifier = RandomForestClassifier(n_estimators=100, max_depth=3, criterion=\"entropy\")\n","    classifier.fit(X[train], y[train])\n","    preds = classifier.predict(X[test])\n","    score = metrics.accuracy_score(preds, y[test])\n","    scores.append(score)\n","\n","    if score > best_score:\n","        best_classifier = classifier\n","        best_score = score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F2UHRB_4HvDW"},"source":["`classifier = RandomForestClassifier(n_estimators=100, max_depth=3, criterion=\"entropy\")`が識別器の定義となる．主なパラメータとして`n_estimators`と`max_depth`と`criterion`がある．\n","\n","- `n_estimators`: 決定木の数\n","- `max_depth`: 決定木の最大の深さ\n","- `criterion`: 分割の品質を計算する関数\n"]},{"cell_type":"markdown","metadata":{"id":"DiO8szpoJMeH"},"source":["## 識別率の計算\n","得られたk個の結果を平均して，識別率を求める．"]},{"cell_type":"code","metadata":{"id":"KFlfL2BlHvHw"},"source":["accuracy = (sum(scores) / len(scores)) * 100\n","msg = 'recognition rate: {accuracy:.2f}%'.format(accuracy=accuracy)\n","print(msg)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"puwLllGzFwcN"},"source":["## グラフの描画\n","識別結果を可視化するためにグラフを作成する．どちらのクラスがどの領域かわかりやすく表示することができる．"]},{"cell_type":"code","metadata":{"id":"D5qMj9hGHvQh"},"source":["import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","subfig = fig.add_subplot(1,1,1)\n","plt.xlim(0, 10000)\n","plt.ylim(20, 50)\n","\n","xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 500),\n","                     np.linspace(plt.ylim()[0], plt.ylim()[1], 500))\n","\n","Z = best_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n","\n","subfig.scatter(car[:,0], car[:,1],color='black')\n","subfig.scatter(human[:,0], human[:,1],color='red')\n","\n","subfig.set_title('08 RandomForest')\n","subfig.set_xlabel('Area')\n","subfig.set_ylabel('complexity')\n","\n","plt.savefig(\"08_graph.png\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBrXoDzTHvUO"},"source":["## 課題\n","1. 木の数（`n_estimators`）と深さ（`max_depth`）を変更すると識別境界はどうなるか．グラフで確認せよ．\n","2. 識別率の最も高くなるパラメータを求めよ．\n","\n","\n","## ヒント\n","1. 値を増やしたり減らしたりして，それぞれどう変わるか確認してみる．\n","2. 決定木の深さが深すぎると過学習になる．"]}]}