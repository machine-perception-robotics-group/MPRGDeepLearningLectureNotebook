{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/02_dnn_simple_pytorch/11_CIFAR_CNN_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJU2RPpSvlQT"
      },
      "source": [
        "# CNNによる画像認識（CIFAR10, PyTorch実装）\n",
        "\n",
        "\n",
        "---\n",
        "## 目的\n",
        "CIFAR10 Datasetを用いて10クラスの物体認識を行う．プログラムの構成は，MNISTによる文字認識のプログラムと同様になっているため，基礎的な説明はそちらを参照して頂きたい．このページでは，MNISTによる文字認識のプログラムとの差分について書いていく．\n",
        "\n",
        "GPUを用いたネットワークの計算を行う．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQGfxWYK_4O"
      },
      "source": [
        "## 準備\n",
        "\n",
        "### Google Colaboratoryの設定確認・変更\n",
        "本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n",
        "**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2tsYagqvloK"
      },
      "source": [
        "## 使用するデータセット\n",
        "\n",
        "### データセット\n",
        "今回の物体認識では，CIFAR10データセットを用いる．CIFAR10データセットは，飛行機や犬などの10クラスの物体が表示されている画像から構成されたデータセットである．\n",
        "\n",
        "![CIFAR10_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176458/b6b43478-c85f-9211-7bc6-227d9b387af5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo4jjpmwvle1"
      },
      "source": [
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートする．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`Use CUDA: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n",
        "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モジュールのインポート\n",
        "from time import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ],
      "metadata": {
        "id": "CL3WmZPkVrKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppjeW5MbysXC"
      },
      "source": [
        "## データセットの読み込みと確認\n",
        "学習データ（CIFAR10データセット）を読み込みます．\n",
        "\n",
        "読み込んだ学習データのサイズを確認します．\n",
        "学習データは5万枚，1つのデータサイズは3x32x32の画像のような形式となっています．\n",
        "これは32x32ピクセルのカラー画像という意味になります．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "K4ataEWnVura"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKi4gTk8vlxe"
      },
      "source": [
        "### CIFAR10データセットの表示\n",
        "CIFAR10データセットに含まれる画像を表示してみます．\n",
        "ここでは，matplotlibを用いて複数の画像を表示させるプログラムを利用します．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cols = 10\n",
        "rows = 2\n",
        "\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(14, 4.8))\n",
        "for r in range(rows):\n",
        "    for c in range(cols):\n",
        "        ax = fig.add_subplot(r+1, cols, c+1)\n",
        "        ax.imshow(train_data[c+r*cols][0].permute(1, 2, 0))\n",
        "        ax.set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qwiqu_pAVwjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDd3iX2zmSV"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "\n",
        "畳み込みニューラルネットワークを定義します．\n",
        "\n",
        "ここでは，畳み込み層２層，全結合層３層から構成されるネットワークとします．\n",
        "\n",
        "1層目の畳み込み層は入力チャンネル数が1，出力する特徴マップ数が16，畳み込むフィルタサイズが3x3です．\n",
        "2層目の畳み込み層は入力チャネル数が16．出力する特徴マップ数が32，畳み込むフィルタサイズは同じく3x3です．\n",
        "１つ目の全結合層は入力ユニット数は`7*7*32`とし，出力は1024としています．\n",
        "次の全結合層入力，出力共に1024，出力層は入力が1024，出力が10です．\n",
        "また，活性化関数として`self.act`にシグモイド関数を定義します．\n",
        "さらに，プーリング処理を行うための`self.pool`を定義します．\n",
        "ここでは，maxpoolingを使用します．\n",
        "これらの各層の構成を`__init__`関数で定義します．\n",
        "\n",
        "次に，`forward`関数では，定義した層を接続して処理するように記述します．\n",
        "`forward`関数の引数`x`は入力データです．\n",
        "それを`__init__`関数で定義した`conv1`に入力し，その出力を活性化関数である`self.act`に与えます．\n",
        "そして，その出力を`self.pool`に与えて，プーリング処理結果を`h`として出力します．\n",
        "2層目の畳み込み層でも同様の手順で処理を行います．\n",
        "\n",
        "畳み込みを適用した後の特徴マップを全結合層へと入力して，識別結果を出力します．\n",
        "まず．畳み込みによって得られた特徴マップの形状（チャンネルx縦x横）を1次元の配列へと変換します．\n",
        "ここで，`view()`を用いることで，`h`の配列を操作します．引数として，変換したい配列のサイズを入力します．\n",
        "まず一つ目の引数の`h.size()[0]`で，`h`の1次元目のサイズを取得し，変換後の配列の1次元目のサイズとして指定します．\n",
        "二つ目の引数の`-1`で任意のサイズを指定します．\n",
        "これにより，`h`を（バッチ数x任意の長さのデータ）の形状へ変換します．\n",
        "変換した`h`を全結合層および活性化関数へと順次入力することで，最終的にクラススコアを返します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNHnp_YczmY3"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
        "        self.l2 = nn.Linear(1024, 1024)\n",
        "        self.l3 = nn.Linear(1024, 10)\n",
        "        self.act = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.pool(self.act(self.conv1(x)))\n",
        "        h = self.pool(self.act(self.conv2(h)))\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.act(self.l1(h))\n",
        "        h = self.act(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dwuvfouzmd7"
      },
      "source": [
        "## ネットワークの作成\n",
        "上のプログラムで定義したネットワークを作成します．\n",
        "\n",
        "`CNN`クラスを呼び出して，ネットワークモデルを定義します．\n",
        "また，GPUを使う場合（`use_cuda == True`）には，ネットワークモデルをGPUメモリ上に配置します．\n",
        "これにより，GPUを用いた演算が可能となります．\n",
        "\n",
        "学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します．\n",
        "また，学習率を0.01，モーメンタムを0.9として引数に与えます．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "id": "9VJ9nh8WVzkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNa9Xe79vAG"
      },
      "source": [
        "## 学習\n",
        "読み込んだMNISTデータセットと作成したネットワークを用いて，学習を行います．\n",
        "\n",
        "1回の誤差を算出するデータ数（ミニバッチサイズ）を64，学習エポック数を10とします．\n",
        "\n",
        "次にデータローダーを定義します．\n",
        "データローダーでは，上で読み込んだデータセット（`train_data`）を用いて，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n",
        "この時，`shuffle=True`と設定することで，読み込むデータを毎回ランダムに指定します．\n",
        "\n",
        "次に，誤差関数を設定します．\n",
        "今回は，分類問題をあつかうため，クロスエントロピー誤差を計算するための`CrossEntropyLoss`を`criterion`として定義します．\n",
        "\n",
        "学習を開始します．\n",
        "\n",
        "各更新において，学習用データと教師データをそれぞれ`image`と`label`とします．\n",
        "学習モデルにimageを与えて各クラスの確率yを取得します．\n",
        "各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
        "また，認識精度も算出します．\n",
        "そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model(image)\n",
        "        \n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_loader),\n",
        "                                                                                 time() - start))"
      ],
      "metadata": {
        "id": "ZApUO8qEV1W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119eIrSmzmw6"
      },
      "source": [
        "## テスト\n",
        "学習したネットワークモデルを用いて評価を行います．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ],
      "metadata": {
        "id": "leFlagpRV3ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzl4N5rC4j5u"
      },
      "source": [
        "## 課題\n",
        "\n",
        "### 1. ネットワークの構造を変更し，認識精度の変化を確認しましょう．\n",
        "\n",
        "**ヒント：ネットワーク構造の変更としては，次のようなものが考えられます．**\n",
        "* 中間層のユニット数，畳み込みのカーネルサイズ\n",
        "* 層の数\n",
        "* 活性化関数\n",
        "  * `nn.Tanh()`や`nn.ReLU()`, `nn.LeakyReLU()`などが考えられます．\n",
        "  * その他のPyTorchで使用できる活性化関数は[こちらページ](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)にまとめられています．\n",
        "\n",
        "\n",
        "### 2. 学習の設定を変更し，認識精度の変化を確認しましょう．\n",
        "\n",
        "**ヒント：プログラムの中で変更で切る設定は次のようなものが存在します．**\n",
        "* ミニバッチサイズ\n",
        "* 学習回数（Epoch数）\n",
        "* 学習率\n",
        "* 最適化手法\n",
        "  * `torch.optim.Adagrad()`や`torch.optim.Adam()`などが考えられます．\n",
        "  * PyTorchで使用できる最適化手法は[こちらのページ](https://pytorch.org/docs/stable/optim.html#algorithms)にまとめられています．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 独自の画像データを用いた推論\n",
        "学習は前述の「CNNによる画像認識（CIFAR10,Pytorch実装）」で実行してください。\n",
        "\n",
        "前述で学習を行ったモデルを用いて、独自の画像データを用いて推論を行います。"
      ],
      "metadata": {
        "id": "rIfV_IWh_saa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Driveの同期\n",
        "\"Mounted at /content/drive\"と表示されれば、正常にマウントできています．\n",
        "\n",
        "現在接続しているサーバ内の/content/driveに自身のGoogle Drive（マイドライブ）をマウントしています．\n"
      ],
      "metadata": {
        "id": "JPdbhPBm_4xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive_path = '/content/drive'\n",
        "drive.mount(drive_path)"
      ],
      "metadata": {
        "id": "ie5qDHU7V59F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モジュールのインポート"
      ],
      "metadata": {
        "id": "d8BepJuF_794"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchsummary\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ],
      "metadata": {
        "id": "1GaLqVkPV78p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ラベルリストの設定\n",
        "CIFAR10のラベルリストを設定する。"
      ],
      "metadata": {
        "id": "2R6qvNl2JHTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = np.array([\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\"])"
      ],
      "metadata": {
        "id": "qjznM5tNJKVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 独自の画像データの読み込み\n",
        "Google Driveのマイドライブに推論させたい画像をアップロードしておきます。\n",
        "\n",
        "ori_pathにアップロードした画像のパスを記述します。画像が表示されれば読み込み成功です。"
      ],
      "metadata": {
        "id": "R0dE4zIiAHlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ori_path = \"MyDrive/sample.png\"\n",
        "\n",
        "ori_path = os.path.join(drive_path, ori_path)\n",
        "print(\"test image path: {}\".format(ori_path))\n",
        "\n",
        "ori_image = Image.open(ori_path).convert('RGB').resize((32, 32))\n",
        "plt.imshow(ori_image)\n",
        "plt.show()\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "image = transform(ori_image).unsqueeze(0)"
      ],
      "metadata": {
        "id": "muM4w4NDV97P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 独自データでの推論"
      ],
      "metadata": {
        "id": "iERqFDpXAeGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 推論の実行\n",
        "with torch.no_grad():\n",
        "  if use_cuda:\n",
        "    image = image.cuda()\n",
        "    \n",
        "  y = model(image)\n",
        "  pred = torch.argmax(y, dim=1)\n",
        "\n",
        "plt.imshow(ori_image)\n",
        "plt.show()\n",
        "\n",
        "print(\"pred label: {}\".format(label_names[pred.item()]))"
      ],
      "metadata": {
        "id": "KTrJ3ejmWDSE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "11_CIFAR_CNN_v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}