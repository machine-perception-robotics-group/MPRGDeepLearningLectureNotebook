{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/13_rnn/01_03_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2tEwyj55RY3"
      },
      "source": [
        "# Recurrent Neural Networkによる電力予測\n",
        "\n",
        "\n",
        "---\n",
        "## 目的\n",
        "Recurrent Neural Networkを使って電力予測を行う．ここで，今回はRecurrent Neural Networkの一種である，Long Short Term Memory（LSTM）を使用する．\n",
        "また，PyTorchで使用されるデータセットオブジェクトの作成を行う．\n",
        "\n",
        "## リカレントニューラルネットワーク\n",
        "リカレントニューラルネットワークは，系列データを扱うことができるネットワークです． \n",
        "例えば，「今日は良い天気です」という文章において，「今日は」，「良い」という時系列データを与えると，次に現れる単語として「天気」を予測するという問題です． \n",
        "リカレントニューラルネットワークを利用することで，過去の系列情報から文脈の流れを考慮した予測ができるようになります． \n",
        "応用例として，30分後の電力を予測する，翌日の株価を予測するなどの予測モデル，音声認識や機械翻訳などがあります．\n",
        "\n",
        "## リカレントニューラルネットワークの種類\n",
        "リカレントニューラルネットワークにはいくつかの種類があります．\n",
        "\n",
        "* Elman Network：一般的なリカレントニューラルネットワーク．１時刻前の情報を内部状態として，現時刻の入力と合わせて中間層に与える\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/RNN.png?raw=true\" width = 500>\n",
        "* Jordan Network：１時刻前の出力層の情報を現時刻の入力と合わせて中間層に与える\n",
        "* Echo state network (ESN)：一部の重みを乱数で初期化し，更新しない．中間層内のユニットは相互結合する\n",
        "* Long Short-Term Memory (LSTM)：内部情報を記憶するメモリセルを持ち，複数のゲートによってメモリセルの情報を書き換えたり出力したりする\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/LSTM.png?raw=true\" width = 500>\n",
        "* Gated Recurrent Unit (GRU)：内部情報の保持方法をLSTMよりもシンプルな構造にしたリカレントニューラルネットワーク \n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/GRU.png?raw=true\" width = 500>\n",
        "* Bidirectional RNN：過去の情報だけでなく，未来の情報も利用する双方向のリカレントニューラルネットワーク\n",
        "\n",
        "## リカレントニューラルネットワークの学習\n",
        "リカレントニューラルネットワークは，時系列データを逐次与えます．\n",
        "この流れを展開するとニューラルネットワークを時間方向につなげた大きなネットワークとみなすことができます．\n",
        "そのため，リカレントニューラルネットワークの学習にもニューラルネットワークと同様に誤差逆伝播法を用いることができます．\n",
        "リカレントニューラルネットワークでの誤差逆伝播法は， Back-propagation through time (BPTT)法と呼ばれています．\n",
        "\n",
        "まず，図の黒矢印に従い，系列データを時刻$t=0$から順伝播します．\n",
        "ネットワークは時刻ごとに別々にあるのではなく，１つのネットワークに対して逐次データを入力します．\n",
        "その時，各時刻における各層の値は変わっていくので，それらを記憶しておきます．\n",
        "また，順伝播時に各時刻における誤差を算出しておきます．\n",
        "\n",
        "時刻$t=T$まで系列データの順伝播が終わると学習開始となります．\n",
        "学習は誤差逆伝播法と同様に，BPTTでも誤差の勾配を求めて結合重みを更新します．\n",
        "その際，時刻をさかのぼるように，時刻$t=T$の出力層から始めます．\n",
        "学習では，以下の3箇所の結合重みを順番に更新します．\n",
        "* 時刻tの出力層から時刻tの中間層間の結合重み\n",
        "* 時刻tの中間層から時刻t-1の中間層間の結合重み\n",
        "* 時刻tの中間層から時刻tの入力層間の結合重み\n",
        "\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/back.png?raw=true\" width = 500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo4jjpmwvle1"
      },
      "source": [
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートする．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCeaCulfvlao"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from os import path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQGfxWYK_4O"
      },
      "source": [
        "### データのダウンロードと確認\n",
        "\n",
        "プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Spzsxbxq5Req"
      },
      "outputs": [],
      "source": [
        "!wget -q http://www.mprg.cs.chubu.ac.jp/tutorial/ML_Lecture/SOLAR/data.zip\n",
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH10vE8xDWJP"
      },
      "source": [
        "データを確認してみます．最初の７つの値が曜日のone-hot vector，次の２４個の値は時間のone-hot vector，残りが電力，気温，湿度です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1GIuGGrDWOU"
      },
      "outputs": [],
      "source": [
        "tmp_data = np.load(\"./data/train/BEMS_RNN_train_data.npy\")\n",
        "tmp_label = np.load(\"./data/train/BEMS_RNN_train_labels.npy\")\n",
        "print(tmp_data[0])\n",
        "print(tmp_data.shape)\n",
        "print(tmp_label[0])\n",
        "print(tmp_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uldeLCrV5RiN"
      },
      "source": [
        "## データセットオブジェクトの作成\n",
        "\n",
        "電力データセットに対する，PyTorchのデータセットオブジェクト (`torch.utils.data.Dataset`) を作成します．\n",
        "`Dataset`は，指定したデータセットを読み込み，学習やテストのためにデータを準備し生成するためのクラスです．\n",
        "これまでの実習で使用したMNISTやCIFARデータセットはPyTorch (torchvision) 内に準備されているデータセットオブジェクトでした．\n",
        "今回用いるデータセットは，torchvisonには存在しないため，自身で定義を行います．\n",
        "\n",
        "まず，`__init__`関数により，必要なデータを読み込みます．\n",
        "この時，`__init__`関数の引数を指定します．\n",
        "`root`は読み込むデータセットを配置しているディレクトリ，`train`は学習またはテストデータのどちらを扱うかを指定する変数，`delay`は入力された情報の何時刻後を正解として用意するかを指定する変数，`time_window`は1サンプルあたり何時刻のデータを準備するかをしてする変数です．\n",
        "\n",
        "まず，`root`および`train`変数から，学習またはテストデータを読み込みます．\n",
        "その後，`delay`で指定した時刻を元に正解データを準備します．\n",
        "最後に，`time_window`で指定した時間窓で1サンプルとなるように，データを作成し，`self.data`および`self.label`にデータを格納します．\n",
        "これにより，`self.data`，`self.label`に入力データおよび正解データを格納します．\n",
        "\n",
        "`__getitem__`関数で，指定したインデックス（`item`）のデータを取り出し，返します．\n",
        "\n",
        "`__len__`関数は，このデータセットが保有するサンプル数を返すように定義を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PnxDTzWG5Rmk"
      },
      "outputs": [],
      "source": [
        "class BEMSDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root=\"./data\", train=True, delay=1, time_window=10):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.train = train\n",
        "        self.delay = delay\n",
        "        self.time_window = time_window\n",
        "\n",
        "        # データの読み込み\n",
        "        if self.train:\n",
        "            data_src = np.load(path.join(self.root, 'train', 'BEMS_RNN_train_data.npy'))\n",
        "            label_src = np.load(path.join(self.root, 'train', 'BEMS_RNN_train_labels.npy'))\n",
        "        else:\n",
        "            data_src  = np.load(path.join(self.root, 'test', 'BEMS_RNN_test_data.npy'))\n",
        "            label_src = np.load(path.join(self.root, 'test', 'BEMS_RNN_test_labels.npy'))\n",
        "\n",
        "        data_src = np.asarray(data_src[:-self.delay])\n",
        "        label_src = np.asarray(label_src[self.delay:])\n",
        "\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        for frame_i in range(len(data_src) - self.time_window):\n",
        "            self.data.append(data_src[frame_i:frame_i+self.time_window])\n",
        "            self.label.append(label_src[frame_i:frame_i+self.time_window])\n",
        "\n",
        "        self.data = np.asarray(self.data)\n",
        "        self.label = np.asarray(self.label)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        d = self.data[item, :]\n",
        "        l = self.label[item, :]\n",
        "        return d, l\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvGpadvk5RqS"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "\n",
        "再帰型ニューラルネットワークを定義します．\n",
        "ここでは，LSTM層1層，全結合層1層から構成されるネットワークとします．\n",
        "\n",
        "LSTM層はRecurrent Neural Networkの一種です．\n",
        "LSTMへの入力サイズはNoneとし，データにより変更できるようにしておきます．\n",
        "\n",
        "`forward`関数では，定義した層を接続して処理するように記述します．\n",
        "このとき，全結合層から出力された結果にくわえて，LSTMの隠れ状態とセル状態も同時に返し，次時刻への入力へと使用します．\n",
        "\n",
        "また，LSTMをはじめとするRecurrent Neural Networkでは，内部に過去の入力情報から計算した値を保持しています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9yXFXGSa5RuT"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, n_hidden, rnn_name):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn_name = rnn_name\n",
        "        if rnn_name == \"RNN\":\n",
        "          self.rnn = nn.RNNCell(34, n_hidden)\n",
        "        elif rnn_name == \"LSTM\":\n",
        "          self.rnn = nn.LSTMCell(34, n_hidden)\n",
        "        elif rnn_name == \"GRU\":\n",
        "          self.rnn = nn.GRUCell(34, n_hidden)\n",
        "        self.l1 = nn.Linear(n_hidden, 1)\n",
        "    \n",
        "    def forward(self, x, hx, cx):\n",
        "        if self.rnn_name == \"RNN\":\n",
        "          hx = self.rnn(x, hx)\n",
        "          h = self.l1(hx)\n",
        "          return h, hx, cx\n",
        "        elif self.rnn_name == \"LSTM\":\n",
        "          hx, cx = self.rnn(x, (hx, cx))\n",
        "          h = self.l1(hx)\n",
        "          return h, hx, cx\n",
        "        elif self.rnn_name == \"GRU\":\n",
        "          hx = self.rnn(x, hx)\n",
        "          h = self.l1(hx)\n",
        "          return h, hx, cx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhw3p5bt5Ryh"
      },
      "source": [
        "## ネットワークの作成\n",
        "上のプログラムで定義したネットワークを作成します．\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Iw8xkuhH5R3T"
      },
      "outputs": [],
      "source": [
        "n_hidden = 128\n",
        "rnn_name = \"LSTM\"\n",
        "\n",
        "model = RNN(n_hidden, rnn_name)\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIM8XOcn_ver"
      },
      "source": [
        "## 学習\n",
        "先ほど定義したデータセットと作成したネットワークを用いて，学習を行います．\n",
        "\n",
        "1回の誤差を算出するデータ数（ミニバッチサイズ）を100，学習エポック数を30とします．\n",
        "また，1サンプルあたりのデータの長さ（time window）を10に指定します．\n",
        "\n",
        "次にデータローダーを定義します．\n",
        "データローダーでは，上で読み込んだデータセット（`train_data`）を用いて，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n",
        "この時，`shuffle=True`と設定することで，読み込むデータを毎回ランダムに指定します．\n",
        "\n",
        "次に，誤差関数を設定します．\n",
        "今回は，連続値を出力する回帰問題をあつかうため，`MSELoss`を`criterion`として定義します．\n",
        "\n",
        "学習を開始します．\n",
        "\n",
        "各更新において，学習用データと教師データをそれぞれ`data`と`label`とします．\n",
        "まず，LSTMの隠れ状態とセル状態である`hx`と`cx`を`torch.zeros`を用いて初期化します．\n",
        "この時，1次元目のサイズはバッチサイズに対応するように，`data`のサイズから自動的に決定します．\n",
        "\n",
        "その後，学習モデルに`data`を与えて各クラスの確率yを取得します．\n",
        "今回はLSTMを用いて時系列データを順次処理するため，for文を用いて，各時刻のデータを順番に入力し，結果を得ます．\n",
        "そして，各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
        "また，認識精度も算出します．\n",
        "そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YKmAy2y_vi5"
      },
      "outputs": [],
      "source": [
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 10\n",
        "time_window = 10\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "train_data = BEMSDataset(root=\"./data\", train=True, delay=1, time_window=time_window)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.MSELoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        hx = torch.zeros(data.size()[1], n_hidden)\n",
        "        cx = torch.zeros(data.size()[1], n_hidden)\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "            hx = hx.cuda()\n",
        "            cx = cx.cuda()\n",
        "        \n",
        "        for idx_window in range(time_window):\n",
        "            y, hx, cx = model(data[idx_window], hx, cx)\n",
        "            loss = criterion(y, label[idx_window])\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    elapsed_time = time() - start\n",
        "    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, total_loss, elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll0rYcEf_vma"
      },
      "source": [
        "## テスト\n",
        "学習したネットワークモデルを用いて評価（予測結果の可視化）を行います．\n",
        "可視化にはmatplotlibを用います"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RxKzGki_vqR"
      },
      "outputs": [],
      "source": [
        "# データセットの読み込み・データローダーの設定\n",
        "test_data = BEMSDataset(root=\"./data\", train=False, delay=1, time_window=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "prediction_result = []\n",
        "        \n",
        "# 評価の実行\n",
        "hx = torch.zeros(1, n_hidden)\n",
        "cx = torch.zeros(1, n_hidden)\n",
        "if use_cuda:\n",
        "    hx = hx.cuda()\n",
        "    cx = cx.cuda()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        y, hx, cx = model(data[0], hx, cx)\n",
        "        \n",
        "        prediction_result.append(y.item())\n",
        "\n",
        "prediction_result = np.array(prediction_result).flatten()\n",
        "\n",
        "\n",
        "# 結果の表示\n",
        "plt.figure()\n",
        "plt.title(rnn_name)\n",
        "plt.plot(test_data.label, color='red', label='true')\n",
        "plt.plot(prediction_result.tolist(), color='blue', label='pred')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEJLA1oraJ2X"
      },
      "source": [
        "## 課題\n",
        "\n",
        "1. LSTM以外の再帰型ニューラルネットワークを用いた場合の結果を確認しましょう\n",
        "    * `RNNCell`や`GRUCell`などがあります．\n",
        "2. 電力予測について，入力データを現在の電力・気温・湿度のみ入力してみましょう"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "01_03_RNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}